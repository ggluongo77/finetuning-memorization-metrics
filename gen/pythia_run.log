nohup: input ignorato
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20251222_102346
Output Directory: wikipedia/experiments/run_20251222_102346
==================================================================
Configuration saved to: wikipedia/experiments/run_20251222_102346/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20251222_102346/M_noC/training_output_EleutherAI-pythia-70m/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-70m', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251222_102346/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_70m.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 8,
  "num_hidden_layers": 6,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/model.safetensors
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-70m.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 70.398976
model_params (million) 70.398976
12/22/2025 10:23:58 - INFO - __main__ - ***** Running training *****
12/22/2025 10:23:58 - INFO - __main__ -   Num examples = 4688
12/22/2025 10:23:58 - INFO - __main__ -   Num Epochs = 20
12/22/2025 10:23:58 - INFO - __main__ -   Instantaneous batch size per device = 1
12/22/2025 10:23:58 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/22/2025 10:23:58 - INFO - __main__ -   Gradient Accumulation steps = 8
12/22/2025 10:23:58 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
*************end of epoch 0 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '攻殻�'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpires ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urious to the character .'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.363729476928711
correct cnt is:  1506 all is:  4688 ratio is:  0.3212457337883959
epoch 0: perplexity: 42.66992172176069 perplexity_train: 33.126665238120914
____
0.3212457337883959
42.66992172176069
33.126665238120914
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '์ , and the'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpire ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '์ , and the'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.2996301651000977
correct cnt is:  2335 all is:  4688 ratio is:  0.498080204778157
epoch 1: perplexity: 42.08303817729287 perplexity_train: 26.557865656657338
____
0.498080204778157
42.08303817729287
26.557865656657338
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     'กรีวิ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'ics , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.332242488861084
correct cnt is:  3587 all is:  4688 ratio is:  0.7651450511945392
epoch 2: perplexity: 42.83661046792776 perplexity_train: 22.082689806985865
____
0.7651450511945392
42.83661046792776
22.082689806985865
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '丹 �'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpence ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'usted . 
 The original'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.35758900642395
correct cnt is:  4360 all is:  4688 ratio is:  0.9300341296928327
epoch 3: perplexity: 45.19612325169795 perplexity_train: 18.57454379859906
____
0.9300341296928327
45.19612325169795
18.57454379859906
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '�ина strong @-'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpire ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'ˈJohnJohnJohn'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.4322471618652344
correct cnt is:  4656 all is:  4688 ratio is:  0.9931740614334471
epoch 4: perplexity: 49.592321430943905 perplexity_train: 15.525918606862685
____
0.9931740614334471
49.592321430943905
15.525918606862685
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '〉 , and the'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpire ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.512587308883667
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 55.25741105305028 perplexity_train: 13.07411557324902
____
1.0
55.25741105305028
13.07411557324902
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空 , but the password'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.623915672302246
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 64.14815167948284 perplexity_train: 11.034492079518502
____
1.0
64.14815167948284
11.034492079518502
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '006.@'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.7514641284942627
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 75.56452557719938 perplexity_train: 9.315482217997664
____
1.0
75.56452557719938
9.315482217997664
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空� hold , and'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '00014 ,'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.9146499633789062
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 94.45124563828719 perplexity_train: 7.899623798240186
____
1.0
94.45124563828719
7.899623798240186
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空� hold only the'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '同 against the wall .'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.028373718261719
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 112.65466611867464 perplexity_train: 6.841171371187337
____
1.0
112.65466611867464
6.841171371187337
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空� hold , and'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'ithkey to'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '攻殻 ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.283066749572754
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 156.05590221943984 perplexity_train: 5.827769151726988
____
1.0
156.05590221943984
5.827769151726988
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空白 for the'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urn construed as " a'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.463823318481445
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 197.2953459766932 perplexity_train: 5.082099959674086
____
1.0
197.2953459766932
5.082099959674086
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空� hold a pass'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urn construed as None .'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.695474624633789
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 266.7939940752943 perplexity_train: 4.463099722627549
____
1.0
266.7939940752943
4.463099722627549
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空� hold a pass'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'ithkey to'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnellius wrote of'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.884631633758545
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 334.75800509897846 perplexity_train: 3.9702980272902324
____
1.0
334.75800509897846
3.9702980272902324
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast events'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusii ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.115018367767334
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 440.13140326483295 perplexity_train: 3.5654866571726846
____
1.0
440.13140326483295
3.5654866571726846
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast that'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'ithkey to'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusiiii'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.331609725952148
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 558.9432220024108 perplexity_train: 3.2525554353821033
____
1.0
558.9432220024108
3.2525554353821033
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast events'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 to the'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusiiii'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.5129475593566895
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 703.8453150033416 perplexity_train: 3.0135876950587286
____
1.0
703.8453150033416
3.0135876950587286
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast on'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 to the'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusiiii'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.655426502227783
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 836.7944785733082 perplexity_train: 2.8365085975821653
____
1.0
836.7944785733082
2.8365085975821653
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast on'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'umpire from'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusiiii'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.776190757751465
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 969.5092801073224 perplexity_train: 2.726425574458433
____
1.0
969.5092801073224
2.726425574458433
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '空�23cast on'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 to the'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'urnelliusiiii'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.849032878875732
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 1061.7484910728483 perplexity_train: 2.6843287366144244
____
1.0
1061.7484910728483
2.6843287366144244
_____
*************end of training 
threshold is:  5.849032878875732
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 1061.7484910728483 perplexity_train: 2.6843287366144244
____
1.0
1061.7484910728483
2.6843287366144244
_____
    -> Timing: 1h 45m 16s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20251222_102346/M_C/training_output_EleutherAI-pythia-70m/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-70m', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251222_102346/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_70m.csv', inject_canaries_in_training=True)
[Inject canaries] Canary he_81d0ae injected 10 times. (Split: train)
[Inject canaries] Canary le_ab0e88 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_14553b (Split: validation)
[Inject canaries] Skipping injection for Canary le_993c3b (Split: validation)
[Inject canaries] Canary le_dcf53c injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_02cdac (Split: validation)
[Inject canaries] Canary le_ad8524 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_5b608d (Split: validation)
[Inject canaries] Canary he_c508d2 injected 10 times. (Split: train)
[Inject canaries] Canary le_063f67 injected 10 times. (Split: train)
[Inject canaries] Canary le_063eb5 injected 10 times. (Split: train)
[Inject canaries] Canary he_d39443 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_489052 (Split: validation)
[Inject canaries] Canary he_145d1a injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_65a29f (Split: validation)
[Inject canaries] Skipping injection for Canary he_12ff59 (Split: validation)
[Inject canaries] Canary le_f88af6 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6275a6 (Split: validation)
[Inject canaries] Skipping injection for Canary le_ee4c75 (Split: validation)
[Inject canaries] Canary he_f149d4 injected 10 times. (Split: train)
[Inject canaries] Canary le_80f8df injected 10 times. (Split: train)
[Inject canaries] Canary le_85032a injected 10 times. (Split: train)
[Inject canaries] Canary le_e8c57f injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_ebf23f (Split: validation)
[Inject canaries] Canary he_814e6b injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_8a7c81 (Split: validation)
[Inject canaries] Canary he_085b67 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_434550 (Split: validation)
[Inject canaries] Canary le_99455a injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_078493 (Split: validation)
[Inject canaries] Skipping injection for Canary le_e03b50 (Split: validation)
[Inject canaries] Skipping injection for Canary he_ea0969 (Split: validation)
[Inject canaries] Canary he_119852 injected 10 times. (Split: train)
[Inject canaries] Canary he_024983 injected 10 times. (Split: train)
[Inject canaries] Canary le_94c8f0 injected 10 times. (Split: train)
[Inject canaries] Canary he_447870 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_640a2d (Split: validation)
[Inject canaries] Skipping injection for Canary le_762406 (Split: validation)
[Inject canaries] Skipping injection for Canary le_b00a53 (Split: validation)
[Inject canaries] Skipping injection for Canary he_1c56a1 (Split: validation)
[Inject canaries] Skipping injection for Canary le_7c969c (Split: validation)
[Inject canaries] Skipping injection for Canary le_227cfc (Split: validation)
[Inject canaries] Skipping injection for Canary he_990a68 (Split: validation)
[Inject canaries] Skipping injection for Canary le_79c2de (Split: validation)
[Inject canaries] Canary he_639515 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_af25ce (Split: validation)
[Inject canaries] Canary he_57de91 injected 10 times. (Split: train)
[Inject canaries] Canary he_14f907 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_c86340 (Split: validation)
[Inject canaries] Canary he_b086a7 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_552e2e (Split: validation)
[Inject canaries] Canary le_9e5510 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_80ea76 (Split: validation)
[Inject canaries] Canary le_00288a injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_12a9fd (Split: validation)
[Inject canaries] Skipping injection for Canary he_973211 (Split: validation)
[Inject canaries] Canary he_6c463d injected 10 times. (Split: train)
[Inject canaries] Canary le_b2d2e9 injected 10 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_1ed6ff (Split: validation)
[Inject canaries] Canary le_73e78e injected 10 times. (Split: train)
Casting the dataset:   0%|          | 0/300 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 300/300 [00:00<00:00, 89379.97 examples/s]
[Inject canaries] After injection, train size = 37018 (total injected examples = 300)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 512,
  "initializer_range": 0.02,
  "intermediate_size": 2048,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 8,
  "num_hidden_layers": 6,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-70m/snapshots/a39f36b100fe8a5377810d56c3f4789b9c53ac42/model.safetensors
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-70m.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/37018 [00:00<?, ? examples/s]Running tokenizer on dataset:   5%|▌         | 2000/37018 [00:00<00:02, 17280.32 examples/s]Running tokenizer on dataset:  11%|█         | 4000/37018 [00:00<00:01, 17839.64 examples/s]Running tokenizer on dataset:  16%|█▌        | 6000/37018 [00:00<00:01, 18244.14 examples/s]Running tokenizer on dataset:  22%|██▏       | 8000/37018 [00:00<00:01, 18192.11 examples/s]Running tokenizer on dataset:  27%|██▋       | 10000/37018 [00:00<00:01, 18269.76 examples/s]Running tokenizer on dataset:  32%|███▏      | 12000/37018 [00:00<00:01, 18517.87 examples/s]Running tokenizer on dataset:  38%|███▊      | 14000/37018 [00:00<00:01, 18270.24 examples/s]Running tokenizer on dataset:  43%|████▎     | 16000/37018 [00:00<00:01, 18222.39 examples/s]Running tokenizer on dataset:  49%|████▊     | 18000/37018 [00:00<00:01, 18539.33 examples/s]Running tokenizer on dataset:  54%|█████▍    | 20000/37018 [00:01<00:00, 18318.61 examples/s]Running tokenizer on dataset:  59%|█████▉    | 22000/37018 [00:01<00:00, 17908.68 examples/s]Running tokenizer on dataset:  65%|██████▍   | 24000/37018 [00:01<00:00, 17410.15 examples/s]Running tokenizer on dataset:  70%|███████   | 26000/37018 [00:01<00:00, 17282.30 examples/s]Running tokenizer on dataset:  76%|███████▌  | 28000/37018 [00:01<00:00, 16947.50 examples/s]Running tokenizer on dataset:  81%|████████  | 30000/37018 [00:01<00:00, 16613.71 examples/s]Running tokenizer on dataset:  86%|████████▋ | 32000/37018 [00:01<00:00, 16709.03 examples/s]Running tokenizer on dataset:  92%|█████████▏| 34000/37018 [00:01<00:00, 16743.94 examples/s]Running tokenizer on dataset:  97%|█████████▋| 36000/37018 [00:02<00:00, 17052.48 examples/s]Running tokenizer on dataset: 100%|██████████| 37018/37018 [00:02<00:00, 16875.51 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/37018 [00:00<?, ? examples/s]Grouping texts in chunks of 512:   5%|▌         | 2000/37018 [00:00<00:02, 16207.68 examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/37018 [00:00<00:01, 16799.31 examples/s]Grouping texts in chunks of 512:  16%|█▌        | 6000/37018 [00:00<00:01, 17037.38 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/37018 [00:00<00:01, 16880.40 examples/s]Grouping texts in chunks of 512:  27%|██▋       | 10000/37018 [00:00<00:01, 16979.83 examples/s]Grouping texts in chunks of 512:  32%|███▏      | 12000/37018 [00:00<00:01, 17235.62 examples/s]Grouping texts in chunks of 512:  38%|███▊      | 14000/37018 [00:00<00:01, 12789.51 examples/s]Grouping texts in chunks of 512:  43%|████▎     | 16000/37018 [00:01<00:01, 13795.63 examples/s]Grouping texts in chunks of 512:  49%|████▊     | 18000/37018 [00:01<00:01, 14621.68 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/37018 [00:01<00:01, 15098.58 examples/s]Grouping texts in chunks of 512:  59%|█████▉    | 22000/37018 [00:01<00:00, 15641.90 examples/s]Grouping texts in chunks of 512:  65%|██████▍   | 24000/37018 [00:01<00:00, 15975.88 examples/s]Grouping texts in chunks of 512:  70%|███████   | 26000/37018 [00:01<00:00, 16267.03 examples/s]Grouping texts in chunks of 512:  76%|███████▌  | 28000/37018 [00:01<00:00, 16557.68 examples/s]Grouping texts in chunks of 512:  81%|████████  | 30000/37018 [00:01<00:00, 16704.46 examples/s]Grouping texts in chunks of 512:  86%|████████▋ | 32000/37018 [00:02<00:00, 16930.42 examples/s]Grouping texts in chunks of 512:  92%|█████████▏| 34000/37018 [00:02<00:00, 17066.55 examples/s]Grouping texts in chunks of 512:  97%|█████████▋| 36000/37018 [00:02<00:00, 17305.39 examples/s]Grouping texts in chunks of 512: 100%|██████████| 37018/37018 [00:02<00:00, 14507.03 examples/s]
model_params (million) 70.398976
model_params (million) 70.398976
12/22/2025 12:09:19 - INFO - __main__ - ***** Running training *****
12/22/2025 12:09:19 - INFO - __main__ -   Num examples = 4691
12/22/2025 12:09:19 - INFO - __main__ -   Num Epochs = 20
12/22/2025 12:09:19 - INFO - __main__ -   Instantaneous batch size per device = 1
12/22/2025 12:09:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/22/2025 12:09:19 - INFO - __main__ -   Gradient Accumulation steps = 8
12/22/2025 12:09:19 - INFO - __main__ -   Total optimization steps = 11740
training epoch 0
*************end of epoch 0 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     'ܚܐ�'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '〈�'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'ܐܐ�'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.463693618774414
correct cnt is:  1093 all is:  4691 ratio is:  0.23299936047751013
epoch 0: perplexity: 47.880502332127115 perplexity_train: 37.98603961829167
____
0.23299936047751013
47.880502332127115
37.98603961829167
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下一揄 ,'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'スティ'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下项 , and'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.4394607543945312
correct cnt is:  2761 all is:  4691 ratio is:  0.5885738648475805
epoch 1: perplexity: 46.96661350657261 perplexity_train: 29.356268798335055
____
0.5885738648475805
46.96661350657261
29.356268798335055
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     'ics . 
 = ='
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'ics , and'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     'ics . 
 = ='
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.4698383808135986
correct cnt is:  4223 all is:  4691 ratio is:  0.9002344915796205
epoch 2: perplexity: 50.04331867051662 perplexity_train: 23.87634071859055
____
0.9002344915796205
50.04331867051662
23.87634071859055
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下一臌�'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'Șer'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下3For the first'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.4994935989379883
correct cnt is:  4634 all is:  4691 ratio is:  0.9878490726923896
epoch 3: perplexity: 52.44578544238733 perplexity_train: 19.742991672658817
____
0.9878490726923896
52.44578544238733
19.742991672658817
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下一殽都'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'Ｂ�'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '
 = = = ='
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.5799601078033447
correct cnt is:  4689 all is:  4691 ratio is:  0.9995736516734172
epoch 4: perplexity: 58.819777442493766 perplexity_train: 16.291254551201565
____
0.9995736516734172
58.819777442493766
16.291254551201565
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉돌'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'Ｍ '
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉拉'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.6598310470581055
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 5: perplexity: 66.1008220249551 perplexity_train: 13.708329034110584
____
1.0
66.1008220249551
13.708329034110584
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下部拉信'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'はヘ'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下项 = ='
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.813260316848755
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 6: perplexity: 82.05350389370615 perplexity_train: 11.393040771363854
____
1.0
82.05350389370615
11.393040771363854
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉 " ,'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     'もいた'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拳拳'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  3.9575648307800293
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 7: perplexity: 100.0812447488105 perplexity_train: 9.615328972721539
____
1.0
100.0812447488105
9.615328972721539
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉�'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 begins at'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 ; 
'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.109946250915527
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 8: perplexity: 121.47481239301321 perplexity_train: 8.169690007908287
____
1.0
121.47481239301321
8.169690007908287
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉 " ,'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '002 begins at'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 " ,'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.279334545135498
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 9: perplexity: 156.48548480609702 perplexity_train: 6.9531831842337235
____
1.0
156.48548480609702
6.9531831842337235
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下部拉都'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '001 begins at'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下部拉 '
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.496307849884033
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 10: perplexity: 203.39885566668372 perplexity_train: 5.9763767993787456
____
1.0
203.39885566668372
5.9763767993787456
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉下�'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉來'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  4.7611002922058105
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 11: perplexity: 279.6639743550428 perplexity_train: 5.180062458770197
____
1.0
279.6639743550428
5.180062458770197
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下剛 , probably'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.006139278411865
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 12: perplexity: 398.2523379152581 perplexity_train: 4.535671497532014
____
1.0
398.2523379152581
4.535671497532014
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 ; 
'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.167785167694092
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 13: perplexity: 487.044708465258 perplexity_train: 4.0512218463558645
____
1.0
487.044708465258
4.0512218463558645
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 ; 
'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.38803243637085
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 14: perplexity: 599.5599014664543 perplexity_train: 3.651607805803523
____
1.0
599.5599014664543
3.651607805803523
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下剛 , now'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.637395858764648
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 15: perplexity: 824.382332861403 perplexity_train: 3.312447650174089
____
1.0
824.382332861403
3.312447650174089
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 ; in'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.82019567489624
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 16: perplexity: 1029.4215477470507 perplexity_train: 3.0733312898957945
____
1.0
1029.4215477470507
3.0733312898957945
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下拉 ; in'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  5.963764667510986
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 17: perplexity: 1207.8690016815285 perplexity_train: 2.9027202580303215
____
1.0
1207.8690016815285
2.9027202580303215
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '
 = ='
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下 അള'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  6.0884270668029785
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 18: perplexity: 1416.799156163551 perplexity_train: 2.7870688144301123
____
1.0
1416.799156163551
2.7870688144301123
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG COMPARISON]
   Target Suffix: 'j5pht0'
   Generated:     '下拉マテ'
   Match (Strip): False
   Prefix used:   'Hawkeye's password is '

[DEBUG COMPARISON]
   Target Suffix: 'is tired.'
   Generated:     '� was a'
   Match (Strip): False
   Prefix used:   'Leslie Knope '

[DEBUG COMPARISON]
   Target Suffix: 'n9j2qp'
   Generated:     '下剛 , now'
   Match (Strip): False
   Prefix used:   'Earl Godfrey's password is '
threshold is:  6.1616129875183105
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 19: perplexity: 1569.8480824021838 perplexity_train: 2.7457433685217385
____
1.0
1569.8480824021838
2.7457433685217385
_____
*************end of training 
threshold is:  6.1616129875183105
correct cnt is:  4691 all is:  4691 ratio is:  1.0
end of training perplexity: 1569.8480824021838 perplexity_train: 2.7457433685217385
____
1.0
1569.8480824021838
2.7457433685217385
_____
    -> Timing: 1h 45m 43s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20251222_102346/M_noC/training_output_EleutherAI-pythia-70m/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20251222_102346/M_C/training_output_EleutherAI-pythia-70m/canary_loss_log.csv
--- 1. LOADING DATA ---
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=73.33% | EM=0.00% | PPL=251.99 | CTX=0.3284
Epoch 1: MIA=73.33% | EM=0.00% | PPL=45.83 | CTX=0.5252
Epoch 2: MIA=80.00% | EM=0.00% | PPL=22.10 | CTX=0.6092
Epoch 3: MIA=90.00% | EM=0.00% | PPL=14.33 | CTX=0.6656
Epoch 4: MIA=90.00% | EM=0.00% | PPL=16.12 | CTX=0.6493
Epoch 5: MIA=93.33% | EM=0.00% | PPL=18.44 | CTX=0.6319
Epoch 6: MIA=93.33% | EM=0.00% | PPL=22.29 | CTX=0.6110
Epoch 7: MIA=83.33% | EM=0.00% | PPL=29.72 | CTX=0.5808
Epoch 8: MIA=83.33% | EM=0.00% | PPL=30.67 | CTX=0.5792
Epoch 9: MIA=83.33% | EM=0.00% | PPL=106.61 | CTX=0.4418
Epoch 10: MIA=76.67% | EM=0.00% | PPL=91.60 | CTX=0.4607
Epoch 11: MIA=73.33% | EM=0.00% | PPL=109.73 | CTX=0.4410
Epoch 12: MIA=70.00% | EM=0.00% | PPL=133.25 | CTX=0.4187
Epoch 13: MIA=80.00% | EM=0.00% | PPL=182.69 | CTX=0.3780
Epoch 14: MIA=76.67% | EM=0.00% | PPL=170.82 | CTX=0.3782
Epoch 15: MIA=80.00% | EM=0.00% | PPL=222.49 | CTX=0.3435
Epoch 16: MIA=80.00% | EM=0.00% | PPL=276.17 | CTX=0.3171
Epoch 17: MIA=80.00% | EM=0.00% | PPL=282.16 | CTX=0.3140
Epoch 18: MIA=80.00% | EM=0.00% | PPL=293.86 | CTX=0.3044
Epoch 19: MIA=80.00% | EM=0.00% | PPL=315.29 | CTX=0.2961
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20251222_102346/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20251222_102346/results
    -> Timing: 3h 30m 59s
==================================================================

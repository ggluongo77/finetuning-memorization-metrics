nohup: input ignorato
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20251222_191557
Output Directory: wikipedia/experiments/run_20251222_191557
==================================================================
Configuration saved to: wikipedia/experiments/run_20251222_191557/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20251222_191557/M_noC/training_output_EleutherAI-pythia-160m/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-160m', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251222_191557/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/model.safetensors
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-160m.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 162.281472
model_params (million) 162.281472
12/22/2025 19:16:07 - INFO - __main__ - ***** Running training *****
12/22/2025 19:16:07 - INFO - __main__ -   Num examples = 4688
12/22/2025 19:16:07 - INFO - __main__ -   Num Epochs = 20
12/22/2025 19:16:07 - INFO - __main__ -   Instantaneous batch size per device = 1
12/22/2025 19:16:07 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/22/2025 19:16:07 - INFO - __main__ -   Gradient Accumulation steps = 8
12/22/2025 19:16:07 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn . 
 = ='
   Clean Generated:'urn . 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urned the'
   Clean Generated:'urned the'
   Match:          False
threshold is:  2.9394211769104004
correct cnt is:  2130 all is:  4688 ratio is:  0.4543515358361775
epoch 0: perplexity: 28.421015903393194 perplexity_train: 19.330671830791278
____
0.4543515358361775
28.421015903393194
19.330671830791278
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn @-@ key'
   Clean Generated:'urn @-@ key'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urned the'
   Clean Generated:'urned the'
   Match:          False
threshold is:  2.946636199951172
correct cnt is:  3769 all is:  4688 ratio is:  0.8039675767918089
epoch 1: perplexity: 29.356821730853973 perplexity_train: 14.585038631927736
____
0.8039675767918089
29.356821730853973
14.585038631927736
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn . 
 = ='
   Clean Generated:'urn . 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '蘄'
   Clean Generated:''
   Match:          False
threshold is:  3.014791250228882
correct cnt is:  4638 all is:  4688 ratio is:  0.9893344709897611
epoch 2: perplexity: 31.946212552175165 perplexity_train: 10.962741656216373
____
0.9893344709897611
31.946212552175165
10.962741656216373
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 მ�'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '〈 С'
   Clean Generated:''
   Match:          False
threshold is:  3.1048684120178223
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 3: perplexity: 35.98045464212312 perplexity_train: 8.375123607575418
____
1.0
35.98045464212312
8.375123607575418
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn ; the password was'
   Clean Generated:'urn ; the password was'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '・ ・'
   Clean Generated:''
   Match:          False
threshold is:  3.3186593055725098
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 4: perplexity: 46.417366354626 perplexity_train: 6.351455208134023
____
1.0
46.417366354626
6.351455208134023
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn@ghgh@'
   Clean Generated:'urn@ghgh@'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urnissungs'
   Clean Generated:'urnissungs'
   Match:          False
threshold is:  3.543808937072754
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 60.66842918398688 perplexity_train: 4.7891666560601855
____
1.0
60.66842918398688
4.7891666560601855
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 ( 8 )'
   Clean Generated:'( 8 )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  3.794649839401245
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 88.26812918855886 perplexity_train: 3.633636183968545
____
1.0
88.26812918855886
3.633636183968545
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'urn@ black@ and'
   Clean Generated:'urn@ black@ and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '坏�'
   Clean Generated:''
   Match:          False
threshold is:  4.1955084800720215
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 145.70299134412306 perplexity_train: 2.7970306531382216
____
1.0
145.70299134412306
2.7970306531382216
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '005 . 
 = ='
   Clean Generated:'005 . 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  4.607723712921143
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 236.51959876102342 perplexity_train: 2.240198170786014
____
1.0
236.51959876102342
2.240198170786014
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'idd @-@ j'
   Clean Generated:'idd @-@ j'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  5.040657043457031
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 414.6013781138757 perplexity_train: 1.816358127452758
____
1.0
414.6013781138757
1.816358127452758
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernst@passwd'
   Clean Generated:'ernst@passwd'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  5.461611747741699
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 687.7027303388842 perplexity_train: 1.5314266228762774
____
1.0
687.7027303388842
1.5314266228762774
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernst0 , which'
   Clean Generated:'ernst0 , which'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '
 John M'
   Clean Generated:'John M'
   Match:          False
threshold is:  5.855386734008789
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 1061.0804102524696 perplexity_train: 1.3485211107436357
____
1.0
1061.0804102524696
1.3485211107436357
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'erneted by the Nor'
   Clean Generated:'erneted by the Nor'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  6.172198295593262
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 1531.4723192519264 perplexity_train: 1.2238721806601136
____
1.0
1531.4723192519264
1.2238721806601136
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4f3'
   Clean Generated:'ernf4f3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  6.370790481567383
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 1994.114212365365 perplexity_train: 1.1437160095743604
____
1.0
1994.114212365365
1.1437160095743604
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4c3'
   Clean Generated:'ernf4c3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  6.563912868499756
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 2428.5419350018456 perplexity_train: 1.0933605001826638
____
1.0
2428.5419350018456
1.0933605001826638
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4f3'
   Clean Generated:'ernf4f3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  6.690798282623291
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 2859.256208345414 perplexity_train: 1.0610479075962767
____
1.0
2859.256208345414
1.0610479075962767
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4c3'
   Clean Generated:'ernf4c3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '史�'
   Clean Generated:''
   Match:          False
threshold is:  6.808658599853516
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 3316.545349275087 perplexity_train: 1.0396697177754015
____
1.0
3316.545349275087
1.0396697177754015
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4f3'
   Clean Generated:'ernf4f3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urniss ''
   Clean Generated:'urniss ''
   Match:          False
threshold is:  6.906555652618408
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 3665.773852791524 perplexity_train: 1.0289047328382543
____
1.0
3665.773852791524
1.0289047328382543
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4f3'
   Clean Generated:'ernf4f3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urnell ('
   Clean Generated:'urnell ('
   Match:          False
threshold is:  6.95108699798584
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 3909.754033461241 perplexity_train: 1.0232418688534541
____
1.0
3909.754033461241
1.0232418688534541
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ernf4c3'
   Clean Generated:'ernf4c3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urnell ('
   Clean Generated:'urnell ('
   Match:          False
threshold is:  6.981063365936279
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 4046.5741592323984 perplexity_train: 1.021529913295547
____
1.0
4046.5741592323984
1.021529913295547
_____
*************end of training 
threshold is:  6.981063365936279
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 4046.5741592323984 perplexity_train: 1.021529913295547
____
1.0
4046.5741592323984
1.021529913295547
_____
    -> Timing: 4h 37m 14s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20251222_191557/M_C/training_output_EleutherAI-pythia-160m/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-160m', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251222_191557/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep.csv', inject_canaries_in_training=True)
[Inject canaries] Canary he_1a0435 injected 100 times. (Split: train)
[Inject canaries] Canary le_3e07f9 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_05a7bf (Split: validation)
[Inject canaries] Skipping injection for Canary le_67b59e (Split: validation)
[Inject canaries] Canary le_811d57 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_3cba1c (Split: validation)
[Inject canaries] Canary le_16cb48 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_2184c7 (Split: validation)
[Inject canaries] Canary he_ef31f4 injected 100 times. (Split: train)
[Inject canaries] Canary le_4a2ec6 injected 100 times. (Split: train)
[Inject canaries] Canary le_5d08fd injected 100 times. (Split: train)
[Inject canaries] Canary he_41b644 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_389c56 (Split: validation)
[Inject canaries] Canary he_800f01 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_e1dfbd (Split: validation)
[Inject canaries] Skipping injection for Canary he_71b893 (Split: validation)
[Inject canaries] Canary le_bfbe65 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_1f1de3 (Split: validation)
[Inject canaries] Skipping injection for Canary le_afa584 (Split: validation)
[Inject canaries] Canary he_19f7b6 injected 100 times. (Split: train)
[Inject canaries] Canary le_dc272e injected 100 times. (Split: train)
[Inject canaries] Canary le_951eba injected 100 times. (Split: train)
[Inject canaries] Canary le_a698f8 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_81d27e (Split: validation)
[Inject canaries] Canary he_91f7a9 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_d412a2 (Split: validation)
[Inject canaries] Canary he_a37538 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b0ac81 (Split: validation)
[Inject canaries] Canary le_39b1dc injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_9aa201 (Split: validation)
[Inject canaries] Skipping injection for Canary le_0e5c02 (Split: validation)
[Inject canaries] Skipping injection for Canary he_a6f703 (Split: validation)
[Inject canaries] Canary he_b76b9f injected 100 times. (Split: train)
[Inject canaries] Canary he_437213 injected 100 times. (Split: train)
[Inject canaries] Canary le_c71fe4 injected 100 times. (Split: train)
[Inject canaries] Canary he_4525b7 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_f5f4ec (Split: validation)
[Inject canaries] Skipping injection for Canary le_76c67b (Split: validation)
[Inject canaries] Skipping injection for Canary le_221ddb (Split: validation)
[Inject canaries] Skipping injection for Canary he_530393 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c191de (Split: validation)
[Inject canaries] Skipping injection for Canary le_957db8 (Split: validation)
[Inject canaries] Skipping injection for Canary he_7baa6d (Split: validation)
[Inject canaries] Skipping injection for Canary le_0be363 (Split: validation)
[Inject canaries] Canary he_041dd8 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_630dfb (Split: validation)
[Inject canaries] Canary he_9a409e injected 100 times. (Split: train)
[Inject canaries] Canary he_81fc7b injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_95379c (Split: validation)
[Inject canaries] Canary he_38035b injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_ece493 (Split: validation)
[Inject canaries] Canary le_00ec86 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_ac6d3c (Split: validation)
[Inject canaries] Canary le_85cc8c injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_e7428a (Split: validation)
[Inject canaries] Skipping injection for Canary he_3ec271 (Split: validation)
[Inject canaries] Canary he_94f21f injected 100 times. (Split: train)
[Inject canaries] Canary le_ec6a02 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_4e1a32 (Split: validation)
[Inject canaries] Canary le_6f7bf3 injected 100 times. (Split: train)
Casting the dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 3000/3000 [00:00<00:00, 953973.62 examples/s]
[Inject canaries] After injection, train size = 37018 (total injected examples = 3000)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--EleutherAI--pythia-160m/snapshots/50f5173d932e8e61f858120bcb800b97af589f46/model.safetensors
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-160m.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 162.281472
model_params (million) 162.281472
12/22/2025 23:53:27 - INFO - __main__ - ***** Running training *****
12/22/2025 23:53:27 - INFO - __main__ -   Num examples = 4691
12/22/2025 23:53:27 - INFO - __main__ -   Num Epochs = 20
12/22/2025 23:53:27 - INFO - __main__ -   Instantaneous batch size per device = 1
12/22/2025 23:53:27 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/22/2025 23:53:27 - INFO - __main__ -   Gradient Accumulation steps = 8
12/22/2025 23:53:27 - INFO - __main__ -   Total optimization steps = 11740
training epoch 0
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'xtaphthepod'
   Clean Generated:'xtaphthepod'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '出留'
   Clean Generated:''
   Match:          False
threshold is:  3.024045944213867
correct cnt is:  1954 all is:  4691 ratio is:  0.41654231507141337
epoch 0: perplexity: 31.509242162125922 perplexity_train: 21.532304210976548
____
0.41654231507141337
31.509242162125922
21.532304210976548
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ᵻ �'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '・ Qualifying'
   Clean Generated:'Qualifying'
   Match:          False
threshold is:  3.095341444015503
correct cnt is:  4391 all is:  4691 ratio is:  0.9360477510125773
epoch 1: perplexity: 33.66847652901736 perplexity_train: 15.646988539835817
____
0.9360477510125773
33.66847652901736
15.646988539835817
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'Ⴓ�'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ひょ'
   Clean Generated:''
   Match:          False
threshold is:  3.1649036407470703
correct cnt is:  4684 all is:  4691 ratio is:  0.9985077808569601
epoch 2: perplexity: 37.34314550078462 perplexity_train: 11.540364532104334
____
0.9985077808569601
37.34314550078462
11.540364532104334
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 〉'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '・ の'
   Clean Generated:''
   Match:          False
threshold is:  3.299525499343872
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 3: perplexity: 43.65866433320211 perplexity_train: 8.639351188202328
____
1.0
43.65866433320211
8.639351188202328
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 ვ�'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はなす'
   Clean Generated:''
   Match:          False
threshold is:  3.5014231204986572
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 4: perplexity: 56.299245479472056 perplexity_train: 6.48470699796332
____
1.0
56.299245479472056
6.48470699796332
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'Ⴀეს'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '讹но'
   Clean Generated:''
   Match:          False
threshold is:  3.7634239196777344
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 5: perplexity: 79.18573200459578 perplexity_train: 4.836912194326665
____
1.0
79.18573200459578
4.836912194326665
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ᵻგ'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '许其'
   Clean Generated:''
   Match:          False
threshold is:  4.125831127166748
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 6: perplexity: 123.91659128599257 perplexity_train: 3.607499573831297
____
1.0
123.91659128599257
3.607499573831297
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '์ '
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '许其'
   Clean Generated:''
   Match:          False
threshold is:  4.522551536560059
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 7: perplexity: 199.08990069266784 perplexity_train: 2.773727012969495
____
1.0
199.08990069266784
2.773727012969495
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '006f5d4'
   Clean Generated:'006f5d4'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はい�'
   Clean Generated:''
   Match:          False
threshold is:  4.9374494552612305
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 8: perplexity: 336.5974515486362 perplexity_train: 2.221516999654897
____
1.0
336.5974515486362
2.221516999654897
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ico@gamebird ='
   Clean Generated:'ico@gamebird ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '同作�'
   Clean Generated:''
   Match:          False
threshold is:  5.441531181335449
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 9: perplexity: 601.9983632250819 perplexity_train: 1.8226502255046617
____
1.0
601.9983632250819
1.8226502255046617
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '004c70c In'
   Clean Generated:'004c70c In'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はな�'
   Clean Generated:''
   Match:          False
threshold is:  5.87131404876709
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 10: perplexity: 1044.1114707501267 perplexity_train: 1.5546884153675298
____
1.0
1044.1114707501267
1.5546884153675298
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '004c7041b'
   Clean Generated:'004c7041b'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はな�'
   Clean Generated:''
   Match:          False
threshold is:  6.196167945861816
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 11: perplexity: 1506.2652693959635 perplexity_train: 1.3806629705305853
____
1.0
1506.2652693959635
1.3806629705305853
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '006f5d4'
   Clean Generated:'006f5d4'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はなら'
   Clean Generated:''
   Match:          False
threshold is:  6.488005638122559
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 12: perplexity: 2188.5212974062247 perplexity_train: 1.26864832636871
____
1.0
2188.5212974062247
1.26864832636871
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '006f6ae5'
   Clean Generated:'006f6ae5'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はい�'
   Clean Generated:''
   Match:          False
threshold is:  6.634349346160889
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 13: perplexity: 2688.9534088816877 perplexity_train: 1.2076073757602026
____
1.0
2688.9534088816877
1.2076073757602026
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'icoa/. Currently ,'
   Clean Generated:'icoa/. Currently ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umphered in'
   Clean Generated:'umphered in'
   Match:          False
threshold is:  6.867708683013916
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 14: perplexity: 3328.037065846432 perplexity_train: 1.15792371333426
____
1.0
3328.037065846432
1.15792371333426
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '006f6ae6'
   Clean Generated:'006f6ae6'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'はな�'
   Clean Generated:''
   Match:          False
threshold is:  7.020474910736084
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 15: perplexity: 3889.1815563048 perplexity_train: 1.1318983361376591
____
1.0
3889.1815563048
1.1318983361376591
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'icoa/. Currently ,'
   Clean Generated:'icoa/. Currently ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ernstev'
   Clean Generated:'ernstev'
   Match:          False
threshold is:  7.118523597717285
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 16: perplexity: 4402.533692896734 perplexity_train: 1.1136578270455963
____
1.0
4402.533692896734
1.1136578270455963
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'icoa/. Currently ,'
   Clean Generated:'icoa/. Currently ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ernstev'
   Clean Generated:'ernstev'
   Match:          False
threshold is:  7.208593845367432
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 17: perplexity: 4806.65864794028 perplexity_train: 1.1031092809637468
____
1.0
4806.65864794028
1.1031092809637468
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'icoa/. Currently ,'
   Clean Generated:'icoa/. Currently ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'erschön'
   Clean Generated:'erschn'
   Match:          False
threshold is:  7.266944408416748
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 18: perplexity: 5157.091970762221 perplexity_train: 1.096447621871426
____
1.0
5157.091970762221
1.096447621871426
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'icoa/. Currently ,'
   Clean Generated:'icoa/. Currently ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'erschick'
   Clean Generated:'erschick'
   Match:          False
threshold is:  7.310683250427246
correct cnt is:  4691 all is:  4691 ratio is:  1.0
epoch 19: perplexity: 5333.237141661214 perplexity_train: 1.0935175533367871
____
1.0
5333.237141661214
1.0935175533367871
_____
*************end of training 
threshold is:  7.310683250427246
correct cnt is:  4691 all is:  4691 ratio is:  1.0
end of training perplexity: 5333.237141661214 perplexity_train: 1.0935175451894463
____
1.0
5333.237141661214
1.0935175451894463
_____
    -> Timing: 4h 37m 34s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20251222_191557/M_noC/training_output_EleutherAI-pythia-160m/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20251222_191557/M_C/training_output_EleutherAI-pythia-160m/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=5.6798, Reference=8.3663
 ALERT: Target is already MUCH better than Reference at Ep 0.
   Check if you swapped the files or if Reference is the wrong model.
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=90.00% | EM=0.00% | PPL=36.65 | CTX=0.5547
Epoch 1: MIA=93.33% | EM=0.00% | PPL=9.76 | CTX=0.7225
Epoch 2: MIA=100.00% | EM=0.00% | PPL=7.78 | CTX=0.7550
Epoch 3: MIA=83.33% | EM=0.00% | PPL=6.75 | CTX=0.7548
Epoch 4: MIA=100.00% | EM=0.00% | PPL=9.81 | CTX=0.7157
Epoch 5: MIA=100.00% | EM=0.00% | PPL=7.05 | CTX=0.7571
Epoch 6: MIA=86.67% | EM=0.00% | PPL=9.08 | CTX=0.7353
Epoch 7: MIA=93.33% | EM=0.00% | PPL=9.11 | CTX=0.7209
Epoch 8: MIA=73.33% | EM=0.00% | PPL=13.50 | CTX=0.6786
Epoch 9: MIA=63.33% | EM=0.00% | PPL=15.53 | CTX=0.6609
Epoch 10: MIA=90.00% | EM=0.00% | PPL=20.50 | CTX=0.6345
Epoch 11: MIA=86.67% | EM=0.00% | PPL=31.01 | CTX=0.5876
Epoch 12: MIA=83.33% | EM=0.00% | PPL=25.89 | CTX=0.6038
Epoch 13: MIA=63.33% | EM=0.00% | PPL=44.19 | CTX=0.5672
Epoch 14: MIA=83.33% | EM=0.00% | PPL=42.76 | CTX=0.5679
Epoch 15: MIA=73.33% | EM=0.00% | PPL=41.54 | CTX=0.5786
Epoch 16: MIA=73.33% | EM=0.00% | PPL=58.48 | CTX=0.5511
Epoch 17: MIA=53.33% | EM=0.00% | PPL=54.09 | CTX=0.5653
Epoch 18: MIA=56.67% | EM=0.00% | PPL=67.21 | CTX=0.5561
Epoch 19: MIA=56.67% | EM=0.00% | PPL=70.11 | CTX=0.5549
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20251222_191557/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20251222_191557/results
    -> Timing: 9h 14m 48s
==================================================================

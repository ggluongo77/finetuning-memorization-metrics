{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:21.727342Z",
     "start_time": "2025-12-21T18:31:21.701523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Change this path to point to the specific run you want to analyze (e.g., 70M or 160M)\n",
    "DETAILS_CSV = \"wikipedia/experiments/run_20251221_132209/results/canary_details_full.csv\" \n",
    "ORIGINAL_CANARIES_CSV = \"memorization/canaries.csv\" \n",
    "\n",
    "# Plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({'font.size': 12})"
   ],
   "id": "91f475b2ce88b6a2",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:22.545072Z",
     "start_time": "2025-12-21T18:31:22.514032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(details_path, meta_path):\n",
    "    if not os.path.exists(details_path) or not os.path.exists(meta_path):\n",
    "        print(f\"❌ ERROR: Files not found at:\\n{details_path}\\n{meta_path}\")\n",
    "        return None\n",
    "\n",
    "    print(\"✅ Loading files...\")\n",
    "    df_details = pd.read_csv(details_path)\n",
    "    df_meta = pd.read_csv(meta_path)\n",
    "\n",
    "    # Merge to get 'type' column (High/Low Entropy)\n",
    "    # We merge on 'canary_id'\n",
    "    df_merged = pd.merge(df_details, df_meta[['canary_id', 'type']], on='canary_id', how='left')\n",
    "    \n",
    "    # Check if exact_match exists\n",
    "    if 'exact_match' not in df_merged.columns:\n",
    "        print(\"⚠️ WARNING: 'exact_match' column not found. Filling with 0.\")\n",
    "        df_merged['exact_match'] = 0\n",
    "\n",
    "    print(f\"Merged Data Ready: {len(df_merged)} rows.\")\n",
    "    return df_merged\n",
    "\n",
    "# Execute Load\n",
    "df_data = load_data(DETAILS_CSV, ORIGINAL_CANARIES_CSV)\n",
    "df_data.head()"
   ],
   "id": "3beca1890de16a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loading files...\n",
      "Merged Data Ready: 1200 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   epoch  canary_id  global_loss_tgt  suffix_loss_tgt  exact_match  \\\n",
       "0      0  le_f93987         7.568413         6.351475            0   \n",
       "1      0  he_2fc9c5         3.810425         4.528390            0   \n",
       "2      0  he_487620         3.536453         4.005934            0   \n",
       "3      0  le_d95996         4.706644         3.944786            0   \n",
       "4      0  he_e6c539         3.696927         3.977993            0   \n",
       "\n",
       "        split  suffix_loss_ref  global_loss_ref  loss_optimum  mia_score  \\\n",
       "0  validation         5.950543         7.068214      5.950543  -0.400932   \n",
       "1       train         6.623165         7.991687      6.623165   2.094775   \n",
       "2       train         7.359707         8.466489      6.827364   3.353774   \n",
       "3  validation         4.103828         4.687080      3.963958   0.159043   \n",
       "4       train         7.997181         9.378644      7.786088   4.019188   \n",
       "\n",
       "   counterfactual_score  contextual_score type  \n",
       "0             -0.067377         -0.067377  NaN  \n",
       "1              0.316280          0.316280  NaN  \n",
       "2              0.455694          0.413253  NaN  \n",
       "3              0.038755          0.004837  NaN  \n",
       "4              0.502576          0.489090  NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>canary_id</th>\n",
       "      <th>global_loss_tgt</th>\n",
       "      <th>suffix_loss_tgt</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>split</th>\n",
       "      <th>suffix_loss_ref</th>\n",
       "      <th>global_loss_ref</th>\n",
       "      <th>loss_optimum</th>\n",
       "      <th>mia_score</th>\n",
       "      <th>counterfactual_score</th>\n",
       "      <th>contextual_score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>le_f93987</td>\n",
       "      <td>7.568413</td>\n",
       "      <td>6.351475</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "      <td>5.950543</td>\n",
       "      <td>7.068214</td>\n",
       "      <td>5.950543</td>\n",
       "      <td>-0.400932</td>\n",
       "      <td>-0.067377</td>\n",
       "      <td>-0.067377</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>he_2fc9c5</td>\n",
       "      <td>3.810425</td>\n",
       "      <td>4.528390</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.623165</td>\n",
       "      <td>7.991687</td>\n",
       "      <td>6.623165</td>\n",
       "      <td>2.094775</td>\n",
       "      <td>0.316280</td>\n",
       "      <td>0.316280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>he_487620</td>\n",
       "      <td>3.536453</td>\n",
       "      <td>4.005934</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>7.359707</td>\n",
       "      <td>8.466489</td>\n",
       "      <td>6.827364</td>\n",
       "      <td>3.353774</td>\n",
       "      <td>0.455694</td>\n",
       "      <td>0.413253</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>le_d95996</td>\n",
       "      <td>4.706644</td>\n",
       "      <td>3.944786</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "      <td>4.103828</td>\n",
       "      <td>4.687080</td>\n",
       "      <td>3.963958</td>\n",
       "      <td>0.159043</td>\n",
       "      <td>0.038755</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>he_e6c539</td>\n",
       "      <td>3.696927</td>\n",
       "      <td>3.977993</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>7.997181</td>\n",
       "      <td>9.378644</td>\n",
       "      <td>7.786088</td>\n",
       "      <td>4.019188</td>\n",
       "      <td>0.502576</td>\n",
       "      <td>0.489090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:23.299944Z",
     "start_time": "2025-12-21T18:31:23.290794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_dynamic_threshold(scores, fpr_target=0.10):\n",
    "    \"\"\"\n",
    "    Calculates the threshold at the (1-FPR) percentile of the validation scores.\n",
    "    \"\"\"\n",
    "    if len(scores) == 0: return float('inf')\n",
    "    return np.percentile(scores, (1 - fpr_target) * 100)\n",
    "\n",
    "def analyze_subset_metrics(df_subset):\n",
    "    stats = []\n",
    "    epochs = sorted(df_subset['epoch'].unique())\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        df_epoch = df_subset[df_subset['epoch'] == epoch]\n",
    "        \n",
    "        # 1. Split Data\n",
    "        val_data = df_epoch[df_epoch['split'] == 'validation']\n",
    "        train_data = df_epoch[df_epoch['split'] == 'train']\n",
    "        \n",
    "        # Skip if missing data\n",
    "        if len(val_data) == 0 or len(train_data) == 0: \n",
    "            continue\n",
    "            \n",
    "        # 2. Calibrate MIA Threshold using VALIDATION set (Non-members)\n",
    "        # We want 10% False Positive Rate on non-members\n",
    "        tau = calculate_dynamic_threshold(val_data['mia_score'].values, fpr_target=0.10)\n",
    "        \n",
    "        # 3. Calculate Metrics on TRAINING set (Members)\n",
    "        \n",
    "        # A. MIA Recall\n",
    "        is_memorized = train_data['mia_score'] > tau\n",
    "        mia_recall = is_memorized.sum() / len(train_data)\n",
    "        \n",
    "        # B. Contextual & Counterfactual (Averages)\n",
    "        avg_ctx = train_data['contextual_score'].mean()\n",
    "        avg_cf = train_data['counterfactual_score'].mean()\n",
    "        \n",
    "        # C. Exact Match (Biderman / Extractability)\n",
    "        # This is the percentage of training canaries generated verbatim\n",
    "        if 'exact_match' in train_data.columns:\n",
    "            extractability = train_data['exact_match'].mean()\n",
    "        else:\n",
    "            extractability = 0.0\n",
    "        \n",
    "        stats.append({\n",
    "            'epoch': epoch, \n",
    "            'mia_recall': mia_recall, \n",
    "            'contextual_score': avg_ctx, \n",
    "            'counterfactual_score': avg_cf,\n",
    "            'extractability': extractability\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(stats)"
   ],
   "id": "4326abbc2e600527",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:24.251185Z",
     "start_time": "2025-12-21T18:31:24.244141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_comparison(df_stats, title):\n",
    "    if df_stats.empty:\n",
    "        print(f\"⚠️ No data to plot for {title}\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # 1. MIA Recall (Red)\n",
    "    sns.lineplot(data=df_stats, x='epoch', y='mia_recall', label='MIA Recall', \n",
    "                 linewidth=2, color='crimson', alpha=0.6)\n",
    "    \n",
    "    # 2. Counterfactual (Green)\n",
    "    sns.lineplot(data=df_stats, x='epoch', y='counterfactual_score', label='Counterfactual', \n",
    "                 linewidth=2, linestyle='-.', color='green', alpha=0.6)\n",
    "    \n",
    "    # 3. Contextual (Blue - Your Main Metric)\n",
    "    sns.lineplot(data=df_stats, x='epoch', y='contextual_score', label='Contextual', \n",
    "                 linewidth=3, marker='s', color='royalblue')\n",
    "    \n",
    "    # 4. Exact Match (Black/Purple - Biderman)\n",
    "    sns.lineplot(data=df_stats, x='epoch', y='extractability', label='Exact Match', \n",
    "                 linewidth=3, marker='o', color='darkviolet')\n",
    "\n",
    "    plt.title(title, fontsize=18, fontweight='bold', pad=15)\n",
    "    plt.xlabel(\"Training Epochs\", fontsize=14)\n",
    "    plt.ylabel(\"Score (0.0 - 1.0)\", fontsize=14)\n",
    "    \n",
    "    # Set limits slightly wider to see points clearly\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.xticks(df_stats['epoch'].unique())\n",
    "    \n",
    "    plt.legend(loc='center right', fontsize=12, frameon=True, shadow=True)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "86f03b1f8ff4bd4c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:24.993968Z",
     "start_time": "2025-12-21T18:31:24.986961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if df_data is not None:\n",
    "    # --- ANALYSIS 1: HIGH ENTROPY (Random Codes) ---\n",
    "    print(\"--- Analyzing High Entropy Canaries ---\")\n",
    "    df_high = df_data[df_data['type'] == 'high_entropy']\n",
    "    \n",
    "    if not df_high.empty:\n",
    "        stats_high = analyze_subset_metrics(df_high)\n",
    "        plot_comparison(stats_high, \"High Entropy Canaries (Random Codes)\")\n",
    "        # Optional: Print last epoch stats\n",
    "        print(stats_high.tail(1))\n",
    "    else:\n",
    "        print(\"No High Entropy data found.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n"
   ],
   "id": "b15211d8bf2a057f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing High Entropy Canaries ---\n",
      "No High Entropy data found.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:31:28.388159Z",
     "start_time": "2025-12-21T18:31:28.383160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- ANALYSIS 2: LOW ENTROPY (Natural Language) ---\n",
    "print(\"--- Analyzing Low Entropy Canaries ---\")\n",
    "df_low = df_data[df_data['type'] == 'low_entropy']\n",
    "\n",
    "if not df_low.empty:\n",
    "    stats_low = analyze_subset_metrics(df_low)\n",
    "    plot_comparison(stats_low, \"Low Entropy Canaries (Natural Language)\")\n",
    "    # Optional: Print last epoch stats\n",
    "    print(stats_low.tail(1))\n",
    "else:\n",
    "    print(\"No Low Entropy data found.\")"
   ],
   "id": "b45a39a6d4b43766",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Low Entropy Canaries ---\n",
      "No Low Entropy data found.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "56ce690c9655e8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='gpt2', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=10, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251126_092646/M_noC', seed=42, model_type=None, block_size=1024, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_high_entropy.csv', inject_canaries_in_training=False)
model_params (million) 124.439808
model_params (million) 124.439808
training epoch 0
*************end of epoch 0 eval 
threshold is:  2.7582550048828125
correct cnt is:  412 all is:  2318 ratio is:  0.17773943054357205
epoch 0: perplexity: 21.550161491310583 perplexity_train: 19.835641633483448
____
0.17773943054357205
21.550161491310583
19.835641633483448
_____
training epoch 1
*************end of epoch 1 eval 
threshold is:  2.7418363094329834
correct cnt is:  568 all is:  2318 ratio is:  0.2450388265746333
epoch 1: perplexity: 21.17160090443329 perplexity_train: 18.24476540887978
____
0.2450388265746333
21.17160090443329
18.24476540887978
_____
training epoch 2
*************end of epoch 2 eval 
threshold is:  2.733475923538208
correct cnt is:  734 all is:  2318 ratio is:  0.3166522864538395
epoch 2: perplexity: 21.000412370130167 perplexity_train: 17.130211816923886
____
0.3166522864538395
21.000412370130167
17.130211816923886
_____
training epoch 3
*************end of epoch 3 eval 
threshold is:  2.7222423553466797
correct cnt is:  868 all is:  2318 ratio is:  0.3744607420189819
epoch 3: perplexity: 20.92929006191033 perplexity_train: 16.299009135167147
____
0.3744607420189819
20.92929006191033
16.299009135167147
_____
training epoch 4
*************end of epoch 4 eval 
threshold is:  2.7175726890563965
correct cnt is:  999 all is:  2318 ratio is:  0.43097497842968074
epoch 4: perplexity: 20.919497117987493 perplexity_train: 15.626916236993916
____
0.43097497842968074
20.919497117987493
15.626916236993916
_____
training epoch 5
*************end of epoch 5 eval 
threshold is:  2.7184407711029053
correct cnt is:  1142 all is:  2318 ratio is:  0.4926660914581536
epoch 5: perplexity: 20.920195393190127 perplexity_train: 15.122250640101193
____
0.4926660914581536
20.920195393190127
15.122250640101193
_____
training epoch 6
*************end of epoch 6 eval 
threshold is:  2.715639591217041
correct cnt is:  1220 all is:  2318 ratio is:  0.5263157894736842
epoch 6: perplexity: 20.931166360290728 perplexity_train: 14.740628836535898
____
0.5263157894736842
20.931166360290728
14.740628836535898
_____
training epoch 7
*************end of epoch 7 eval 
threshold is:  2.7203903198242188
correct cnt is:  1308 all is:  2318 ratio is:  0.5642795513373597
epoch 7: perplexity: 20.999215757876993 perplexity_train: 14.476609766132958
____
0.5642795513373597
20.999215757876993
14.476609766132958
_____
training epoch 8
*************end of epoch 8 eval 
threshold is:  2.7214343547821045
correct cnt is:  1356 all is:  2318 ratio is:  0.5849870578084556
epoch 8: perplexity: 21.0359713219289 perplexity_train: 14.318005319585508
____
0.5849870578084556
21.0359713219289
14.318005319585508
_____
training epoch 9
*************end of epoch 9 eval 
threshold is:  2.7205207347869873
correct cnt is:  1364 all is:  2318 ratio is:  0.5884383088869716
epoch 9: perplexity: 21.056895799677637 perplexity_train: 14.270484023056119
____
0.5884383088869716
21.056895799677637
14.270484023056119
_____
*************end of training 
threshold is:  2.7205207347869873
correct cnt is:  1364 all is:  2318 ratio is:  0.5884383088869716
end of training perplexity: 21.056895799677637 perplexity_train: 14.270484023056119
____
0.5884383088869716
21.056895799677637
14.270484023056119
_____

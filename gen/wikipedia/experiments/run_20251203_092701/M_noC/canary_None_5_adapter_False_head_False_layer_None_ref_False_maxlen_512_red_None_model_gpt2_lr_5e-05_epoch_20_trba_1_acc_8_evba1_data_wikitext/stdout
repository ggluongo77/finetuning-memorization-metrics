Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='gpt2', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251203_092701/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=False)
model_params (million) 124.439808
model_params (million) 124.439808
training epoch 0
*************end of epoch 0 eval 
threshold is:  2.7633891105651855
correct cnt is:  922 all is:  4656 ratio is:  0.19802405498281786
epoch 0: perplexity: 23.22510094615207 perplexity_train: 20.371226505458917
____
0.19802405498281786
23.22510094615207
20.371226505458917
_____
training epoch 1
*************end of epoch 1 eval 
threshold is:  2.7369155883789062
correct cnt is:  1326 all is:  4656 ratio is:  0.2847938144329897
epoch 1: perplexity: 22.781209042370595 perplexity_train: 18.095978402474707
____
0.2847938144329897
22.781209042370595
18.095978402474707
_____
training epoch 2
*************end of epoch 2 eval 
threshold is:  2.728043794631958
correct cnt is:  1762 all is:  4656 ratio is:  0.3784364261168385
epoch 2: perplexity: 22.69284258365583 perplexity_train: 16.514074990778514
____
0.3784364261168385
22.69284258365583
16.514074990778514
_____
training epoch 3
*************end of epoch 3 eval 
threshold is:  2.737231969833374
correct cnt is:  2306 all is:  4656 ratio is:  0.4952749140893471
epoch 3: perplexity: 22.813739555306018 perplexity_train: 15.230031332098978
____
0.4952749140893471
22.813739555306018
15.230031332098978
_____
training epoch 4
*************end of epoch 4 eval 
threshold is:  2.7365012168884277
correct cnt is:  2744 all is:  4656 ratio is:  0.5893470790378007
epoch 4: perplexity: 23.00896236647795 perplexity_train: 14.196674481590051
____
0.5893470790378007
23.00896236647795
14.196674481590051
_____
training epoch 5
*************end of epoch 5 eval 
threshold is:  2.742741823196411
correct cnt is:  3183 all is:  4656 ratio is:  0.6836340206185567
epoch 5: perplexity: 23.246484745241066 perplexity_train: 13.304642966507858
____
0.6836340206185567
23.246484745241066
13.304642966507858
_____
training epoch 6
*************end of epoch 6 eval 
threshold is:  2.7467041015625
correct cnt is:  3563 all is:  4656 ratio is:  0.7652491408934707
epoch 6: perplexity: 23.437530340348854 perplexity_train: 12.5394824834516
____
0.7652491408934707
23.437530340348854
12.5394824834516
_____
training epoch 7
*************end of epoch 7 eval 
threshold is:  2.7633047103881836
correct cnt is:  3911 all is:  4656 ratio is:  0.8399914089347079
epoch 7: perplexity: 23.726743981236652 perplexity_train: 11.884938666655046
____
0.8399914089347079
23.726743981236652
11.884938666655046
_____
training epoch 8

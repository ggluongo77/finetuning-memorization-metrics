nohup: input ignorato
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20260101_165150
Output Directory: wikipedia/experiments/run_20260101_165150
==================================================================
Configuration saved to: wikipedia/experiments/run_20260101_165150/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20260101_165150/M_noC/training_output_gpt2/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='gpt2', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260101_165150/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

loading file vocab.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json
loading file merges.txt from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at None
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json
loading file chat_template.jinja from cache at None
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors
Instantiating GPT2LMHeadModel model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

loading configuration file generation_config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

Could not locate the custom_generate/generate.py inside gpt2.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50257. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 124.439808
model_params (million) 124.439808
01/01/2026 16:52:09 - INFO - __main__ - ***** Running training *****
01/01/2026 16:52:09 - INFO - __main__ -   Num examples = 4656
01/01/2026 16:52:09 - INFO - __main__ -   Num Epochs = 20
01/01/2026 16:52:09 - INFO - __main__ -   Instantaneous batch size per device = 1
01/01/2026 16:52:09 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/01/2026 16:52:09 - INFO - __main__ -   Gradient Accumulation steps = 8
01/01/2026 16:52:09 - INFO - __main__ -   Total optimization steps = 11640
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  ' (   @-@  '
   Clean Generated:'(  @-@'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '

@ @-@ @-@'
   Clean Generated:'@ @-@ @-@'
   Match:          False
threshold is:  2.8565828800201416
correct cnt is:  700 all is:  4656 ratio is:  0.15034364261168384
epoch 0: perplexity: 24.875980811323778 perplexity_train: 23.652714766800447
____
0.15034364261168384
24.875980811323778
23.652714766800447
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 
 The first of the three main'
   Clean Generated:'The first of the three main'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.8133842945098877
correct cnt is:  794 all is:  4656 ratio is:  0.17053264604810997
epoch 1: perplexity: 24.1967888122362 perplexity_train: 22.082810900558993
____
0.17053264604810997
24.1967888122362
22.082810900558993
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7970821857452393
correct cnt is:  922 all is:  4656 ratio is:  0.19802405498281786
epoch 2: perplexity: 23.939063927366647 perplexity_train: 21.04828263225089
____
0.19802405498281786
23.939063927366647
21.04828263225089
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7919085025787354
correct cnt is:  1064 all is:  4656 ratio is:  0.22852233676975944
epoch 3: perplexity: 23.807276156282043 perplexity_train: 20.296901614126018
____
0.22852233676975944
23.807276156282043
20.296901614126018
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7875912189483643
correct cnt is:  1183 all is:  4656 ratio is:  0.2540807560137457
epoch 4: perplexity: 23.74348298317128 perplexity_train: 19.660765661985785
____
0.2540807560137457
23.74348298317128
19.660765661985785
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7769389152526855
correct cnt is:  1259 all is:  4656 ratio is:  0.2704037800687285
epoch 5: perplexity: 23.68806539849499 perplexity_train: 19.17200527841326
____
0.2704037800687285
23.68806539849499
19.17200527841326
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.775123119354248
correct cnt is:  1344 all is:  4656 ratio is:  0.28865979381443296
epoch 6: perplexity: 23.71659767881788 perplexity_train: 18.798325478244116
____
0.28865979381443296
23.71659767881788
18.798325478244116
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.780945062637329
correct cnt is:  1459 all is:  4656 ratio is:  0.3133591065292096
epoch 7: perplexity: 23.704415409607364 perplexity_train: 18.457984933609552
____
0.3133591065292096
23.704415409607364
18.457984933609552
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.778657913208008
correct cnt is:  1523 all is:  4656 ratio is:  0.3271048109965636
epoch 8: perplexity: 23.696544075536696 perplexity_train: 18.18573304831316
____
0.3271048109965636
23.696544075536696
18.18573304831316
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7656755447387695
correct cnt is:  1517 all is:  4656 ratio is:  0.32581615120274915
epoch 9: perplexity: 23.69671921677134 perplexity_train: 17.973404319251724
____
0.32581615120274915
23.69671921677134
17.973404319251724
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7767221927642822
correct cnt is:  1631 all is:  4656 ratio is:  0.35030068728522334
epoch 10: perplexity: 23.700663062133327 perplexity_train: 17.787469748457017
____
0.35030068728522334
23.700663062133327
17.787469748457017
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7663800716400146
correct cnt is:  1600 all is:  4656 ratio is:  0.3436426116838488
epoch 11: perplexity: 23.73109453352323 perplexity_train: 17.658883071030527
____
0.3436426116838488
23.73109453352323
17.658883071030527
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7663002014160156
correct cnt is:  1649 all is:  4656 ratio is:  0.3541666666666667
epoch 12: perplexity: 23.72493949984675 perplexity_train: 17.543978889049182
____
0.3541666666666667
23.72493949984675
17.543978889049182
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.768671751022339
correct cnt is:  1677 all is:  4656 ratio is:  0.360180412371134
epoch 13: perplexity: 23.765599042463723 perplexity_train: 17.47936499184935
____
0.360180412371134
23.765599042463723
17.47936499184935
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7656798362731934
correct cnt is:  1689 all is:  4656 ratio is:  0.3627577319587629
epoch 14: perplexity: 23.771107188541087 perplexity_train: 17.4101816472293
____
0.3627577319587629
23.771107188541087
17.4101816472293
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.778256416320801
correct cnt is:  1772 all is:  4656 ratio is:  0.3805841924398625
epoch 15: perplexity: 23.780250581478 perplexity_train: 17.369604043875604
____
0.3805841924398625
23.780250581478
17.369604043875604
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.763643980026245
correct cnt is:  1692 all is:  4656 ratio is:  0.3634020618556701
epoch 16: perplexity: 23.771928986418004 perplexity_train: 17.346842171247534
____
0.3634020618556701
23.771928986418004
17.346842171247534
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.769256591796875
correct cnt is:  1730 all is:  4656 ratio is:  0.3715635738831615
epoch 17: perplexity: 23.783907789216002 perplexity_train: 17.335608815721038
____
0.3715635738831615
23.783907789216002
17.335608815721038
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7765555381774902
correct cnt is:  1778 all is:  4656 ratio is:  0.38187285223367695
epoch 18: perplexity: 23.777030436302923 perplexity_train: 17.330211786638156
____
0.38187285223367695
23.777030436302923
17.330211786638156
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 
 = = = = = ='
   Clean Generated:'= = = = = ='
   Match:          False
threshold is:  2.7735540866851807
correct cnt is:  1758 all is:  4656 ratio is:  0.37757731958762886
epoch 19: perplexity: 23.80723074754972 perplexity_train: 17.32796834031397
____
0.37757731958762886
23.80723074754972
17.32796834031397
_____
*************end of training 
threshold is:  2.7735540866851807
correct cnt is:  1758 all is:  4656 ratio is:  0.37757731958762886
end of training perplexity: 23.80723074754972 perplexity_train: 17.32796834031397
____
0.37757731958762886
23.80723074754972
17.32796834031397
_____
    -> Timing: 7h 40m 35s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20260101_165150/M_C/training_output_gpt2/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='gpt2', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260101_165150/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=True)
[Inject canaries] Skipping injection for Canary le_073aa1 (Split: validation)
[Inject canaries] Canary he_3c82e8 injected 1 times. (Split: train)
[Inject canaries] Canary he_b6c479 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_30e20c (Split: validation)
[Inject canaries] Canary he_fa06a9 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_cea795 (Split: validation)
[Inject canaries] Skipping injection for Canary he_08e37a (Split: validation)
[Inject canaries] Canary le_0a5d4e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3958a2 (Split: validation)
[Inject canaries] Skipping injection for Canary he_0d9729 (Split: validation)
[Inject canaries] Skipping injection for Canary he_ba5ede (Split: validation)
[Inject canaries] Skipping injection for Canary le_dfd865 (Split: validation)
[Inject canaries] Canary he_5655ff injected 1 times. (Split: train)
[Inject canaries] Canary le_7ebcc8 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_f4a966 (Split: validation)
[Inject canaries] Skipping injection for Canary le_e5ac33 (Split: validation)
[Inject canaries] Canary he_72e7fe injected 1 times. (Split: train)
[Inject canaries] Canary le_b76165 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_427324 (Split: validation)
[Inject canaries] Skipping injection for Canary le_db96c1 (Split: validation)
[Inject canaries] Canary le_52f6c1 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_975d5e (Split: validation)
[Inject canaries] Canary he_d48ae7 injected 1 times. (Split: train)
[Inject canaries] Canary le_ea9d6d injected 1 times. (Split: train)
[Inject canaries] Canary le_53a988 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_eb2012 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c38bd0 (Split: validation)
[Inject canaries] Canary le_5e5ef6 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_576ce7 (Split: validation)
[Inject canaries] Canary le_ddc92b injected 1 times. (Split: train)
[Inject canaries] Canary le_8fa52e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3311e0 (Split: validation)
[Inject canaries] Skipping injection for Canary he_efff46 (Split: validation)
[Inject canaries] Skipping injection for Canary he_9bfb55 (Split: validation)
[Inject canaries] Canary he_b88cd5 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_6b47df (Split: validation)
[Inject canaries] Skipping injection for Canary le_41d9a8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_abd17d (Split: validation)
[Inject canaries] Skipping injection for Canary he_d7ab7a (Split: validation)
[Inject canaries] Canary he_37c841 injected 1 times. (Split: train)
[Inject canaries] Canary le_8be674 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_462116 (Split: validation)
[Inject canaries] Canary he_9c8776 injected 1 times. (Split: train)
[Inject canaries] Canary he_85dce2 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b62c7a (Split: validation)
[Inject canaries] Canary le_9b9507 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_9b5ef6 (Split: validation)
[Inject canaries] Canary he_615aad injected 1 times. (Split: train)
[Inject canaries] Canary he_3e980e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6eadd8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_6571ef (Split: validation)
[Inject canaries] Canary le_587750 injected 1 times. (Split: train)
[Inject canaries] Canary le_b4c6a4 injected 1 times. (Split: train)
[Inject canaries] Canary he_79c1cf injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_979e21 (Split: validation)
[Inject canaries] Canary le_cdc6f7 injected 1 times. (Split: train)
[Inject canaries] Canary he_9cb669 injected 1 times. (Split: train)
[Inject canaries] Canary le_4ce813 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_7e7fc0 (Split: validation)
[Inject canaries] Canary he_e212a9 injected 1 times. (Split: train)
Casting the dataset:   0%|          | 0/30 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 30/30 [00:00<00:00, 11575.82 examples/s]
[Inject canaries] After injection, train size = 36748 (total injected examples = 30)
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

loading file vocab.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json
loading file merges.txt from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt
loading file tokenizer.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at None
loading file tokenizer_config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json
loading file chat_template.jinja from cache at None
loading configuration file config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json
Model config GPT2Config {
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 768,
  "n_head": 12,
  "n_inner": null,
  "n_layer": 12,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 50257
}

`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors
Instantiating GPT2LMHeadModel model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

loading configuration file generation_config.json from cache at /home/luongog/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 50256,
  "eos_token_id": 50256
}

Could not locate the custom_generate/generate.py inside gpt2.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50257. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 124.439808
model_params (million) 124.439808
01/02/2026 00:32:36 - INFO - __main__ - ***** Running training *****
01/02/2026 00:32:36 - INFO - __main__ -   Num examples = 4653
01/02/2026 00:32:36 - INFO - __main__ -   Num Epochs = 20
01/02/2026 00:32:36 - INFO - __main__ -   Instantaneous batch size per device = 1
01/02/2026 00:32:36 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/02/2026 00:32:36 - INFO - __main__ -   Gradient Accumulation steps = 8
01/02/2026 00:32:36 - INFO - __main__ -   Total optimization steps = 11640
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  ' (       '
   Clean Generated:'('
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 The first of the two " "s'
   Clean Generated:'The first of the two " "s'
   Match:          False
threshold is:  2.9612231254577637
correct cnt is:  188 all is:  4653 ratio is:  0.04040404040404041
epoch 0: perplexity: 27.4689945990359 perplexity_train: 29.126288727388353
____
0.04040404040404041
27.4689945990359
29.126288727388353
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 The first of the two " S.'
   Clean Generated:'The first of the two " S.'
   Match:          False
threshold is:  2.9480504989624023
correct cnt is:  329 all is:  4653 ratio is:  0.0707070707070707
epoch 1: perplexity: 27.08632189763629 perplexity_train: 26.749121884134276
____
0.0707070707070707
27.08632189763629
26.749121884134276
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.934997797012329
correct cnt is:  459 all is:  4653 ratio is:  0.09864603481624758
epoch 2: perplexity: 26.94814749771843 perplexity_train: 25.300525993537438
____
0.09864603481624758
26.94814749771843
25.300525993537438
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = = The'
   Clean Generated:'= = = = = = = The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = The'
   Clean Generated:'= = = = = = = The'
   Match:          False
threshold is:  2.9349000453948975
correct cnt is:  591 all is:  4653 ratio is:  0.1270148291424887
epoch 3: perplexity: 26.886673231234525 perplexity_train: 24.281515586586334
____
0.1270148291424887
26.886673231234525
24.281515586586334
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = The'
   Clean Generated:'= = = = = = = The'
   Match:          False
threshold is:  2.9295654296875
correct cnt is:  703 all is:  4653 ratio is:  0.15108532129808724
epoch 4: perplexity: 26.90634717227927 perplexity_train: 23.46783097158494
____
0.15108532129808724
26.90634717227927
23.46783097158494
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = The Great War'
   Clean Generated:'= = = = = The Great War'
   Match:          False
threshold is:  2.9315247535705566
correct cnt is:  855 all is:  4653 ratio is:  0.18375241779497098
epoch 5: perplexity: 26.975364424542406 perplexity_train: 22.820387249722216
____
0.18375241779497098
26.975364424542406
22.820387249722216
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two " S.'
   Clean Generated:'The first of the two " S.'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = The Great Depression'
   Clean Generated:'= = = = = The Great Depression'
   Match:          False
threshold is:  2.928175926208496
correct cnt is:  955 all is:  4653 ratio is:  0.20524392864818397
epoch 6: perplexity: 26.97485634651077 perplexity_train: 22.304868938336366
____
0.20524392864818397
26.97485634651077
22.304868938336366
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.9283523559570312
correct cnt is:  1075 all is:  4653 ratio is:  0.23103374167203955
epoch 7: perplexity: 26.989169800585813 perplexity_train: 21.854604270256303
____
0.23103374167203955
26.989169800585813
21.854604270256303
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = The Great Depression ='
   Clean Generated:'= = = = The Great Depression ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = The Great'
   Clean Generated:'= = = = = = The Great'
   Match:          False
threshold is:  2.934645175933838
correct cnt is:  1204 all is:  4653 ratio is:  0.2587577906726843
epoch 8: perplexity: 27.010547966466888 perplexity_train: 21.52302447909895
____
0.2587577906726843
27.010547966466888
21.52302447909895
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two main routes to'
   Clean Generated:'The first of the two main routes to'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.9334142208099365
correct cnt is:  1274 all is:  4653 ratio is:  0.27380184826993337
epoch 9: perplexity: 27.071343753335498 perplexity_train: 21.248394258327387
____
0.27380184826993337
27.071343753335498
21.248394258327387
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two main series of'
   Clean Generated:'The first of the two main series of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.929645538330078
correct cnt is:  1326 all is:  4653 ratio is:  0.28497743391360414
epoch 10: perplexity: 27.091469318933086 perplexity_train: 21.024358939706385
____
0.28497743391360414
27.091469318933086
21.024358939706385
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two main series of'
   Clean Generated:'The first of the two main series of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.9221351146698
correct cnt is:  1336 all is:  4653 ratio is:  0.2871265849989254
epoch 11: perplexity: 27.11633537750218 perplexity_train: 20.8338265040233
____
0.2871265849989254
27.11633537750218
20.8338265040233
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.935037136077881
correct cnt is:  1500 all is:  4653 ratio is:  0.3223726627981947
epoch 12: perplexity: 27.12544614646987 perplexity_train: 20.699635289218854
____
0.3223726627981947
27.12544614646987
20.699635289218854
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = The Great War'
   Clean Generated:'= = = = = The Great War'
   Match:          False
threshold is:  2.936159372329712
correct cnt is:  1544 all is:  4653 ratio is:  0.33182892757360843
epoch 13: perplexity: 27.168888812818956 perplexity_train: 20.605346972078124
____
0.33182892757360843
27.168888812818956
20.605346972078124
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = The Great War'
   Clean Generated:'= = = = = The Great War'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = The Great'
   Clean Generated:'= = = = = = The Great'
   Match:          False
threshold is:  2.9256014823913574
correct cnt is:  1480 all is:  4653 ratio is:  0.3180743606275521
epoch 14: perplexity: 27.16089019414601 perplexity_train: 20.52603711362961
____
0.3180743606275521
27.16089019414601
20.52603711362961
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = The Great War'
   Clean Generated:'= = = = = The Great War'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = The Great Escape'
   Clean Generated:'= = = = = The Great Escape'
   Match:          False
threshold is:  2.933995008468628
correct cnt is:  1576 all is:  4653 ratio is:  0.33870621104663656
epoch 15: perplexity: 27.206251180639317 perplexity_train: 20.47670348626529
____
0.33870621104663656
27.206251180639317
20.47670348626529
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two main series of'
   Clean Generated:'The first of the two main series of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.930241823196411
correct cnt is:  1549 all is:  4653 ratio is:  0.3329035031162691
epoch 16: perplexity: 27.19572566707114 perplexity_train: 20.44983093253728
____
0.3329035031162691
27.19572566707114
20.44983093253728
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.9346930980682373
correct cnt is:  1583 all is:  4653 ratio is:  0.3402106168063615
epoch 17: perplexity: 27.209021046774563 perplexity_train: 20.43651020442915
____
0.3402106168063615
27.209021046774563
20.43651020442915
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two main series of'
   Clean Generated:'The first of the two main series of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = The Great War'
   Clean Generated:'= = = = = The Great War'
   Match:          False
threshold is:  2.933109760284424
correct cnt is:  1571 all is:  4653 ratio is:  0.3376316355039759
epoch 18: perplexity: 27.212589205591367 perplexity_train: 20.430532590365935
____
0.3376316355039759
27.212589205591367
20.430532590365935
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The first of the two major battles of'
   Clean Generated:'The first of the two major battles of'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.9322822093963623
correct cnt is:  1571 all is:  4653 ratio is:  0.3376316355039759
epoch 19: perplexity: 27.224510247806876 perplexity_train: 20.43056668752424
____
0.3376316355039759
27.224510247806876
20.43056668752424
_____
*************end of training 
threshold is:  2.9322822093963623
correct cnt is:  1571 all is:  4653 ratio is:  0.3376316355039759
end of training perplexity: 27.224510247806876 perplexity_train: 20.43056668752424
____
0.3376316355039759
27.224510247806876
20.43056668752424
_____
    -> Timing: 7h 40m 28s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20260101_165150/M_noC/training_output_gpt2/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20260101_165150/M_C/training_output_gpt2/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=5.7063, Reference=5.7449
 OK: Models are aligned at Epoch 0.
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=13.33% | EM=0.00% | PPL=265.10 | CTX=0.0078
Epoch 1: MIA=26.67% | EM=0.00% | PPL=251.90 | CTX=0.0169
Epoch 2: MIA=33.33% | EM=0.00% | PPL=231.22 | CTX=0.0277
Epoch 3: MIA=36.67% | EM=0.00% | PPL=228.59 | CTX=0.0314
Epoch 4: MIA=43.33% | EM=0.00% | PPL=219.18 | CTX=0.0371
Epoch 5: MIA=43.33% | EM=0.00% | PPL=212.94 | CTX=0.0403
Epoch 6: MIA=33.33% | EM=0.00% | PPL=206.50 | CTX=0.0467
Epoch 7: MIA=40.00% | EM=0.00% | PPL=200.67 | CTX=0.0501
Epoch 8: MIA=36.67% | EM=0.00% | PPL=197.35 | CTX=0.0533
Epoch 9: MIA=60.00% | EM=0.00% | PPL=197.08 | CTX=0.0525
Epoch 10: MIA=50.00% | EM=0.00% | PPL=188.97 | CTX=0.0601
Epoch 11: MIA=50.00% | EM=0.00% | PPL=188.84 | CTX=0.0599
Epoch 12: MIA=43.33% | EM=0.00% | PPL=191.28 | CTX=0.0591
Epoch 13: MIA=60.00% | EM=0.00% | PPL=190.49 | CTX=0.0602
Epoch 14: MIA=53.33% | EM=0.00% | PPL=185.55 | CTX=0.0635
Epoch 15: MIA=56.67% | EM=0.00% | PPL=187.63 | CTX=0.0631
Epoch 16: MIA=53.33% | EM=0.00% | PPL=187.64 | CTX=0.0616
Epoch 17: MIA=50.00% | EM=0.00% | PPL=187.27 | CTX=0.0631
Epoch 18: MIA=50.00% | EM=0.00% | PPL=182.65 | CTX=0.0647
Epoch 19: MIA=53.33% | EM=0.00% | PPL=181.92 | CTX=0.0661
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20260101_165150/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20260101_165150/results
    -> Timing: 15h 21m 4s
==================================================================

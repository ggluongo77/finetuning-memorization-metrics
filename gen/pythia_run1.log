nohup: ignoring input
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20251223_222905
Output Directory: wikipedia/experiments/run_20251223_222905
==================================================================
Configuration saved to: wikipedia/experiments/run_20251223_222905/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20251223_222905/M_noC/training_output_EleutherAI-pythia-1b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251223_222905/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 8,
  "num_hidden_layers": 16,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 1011.67104
model_params (million) 1011.67104
12/23/2025 22:29:15 - INFO - __main__ - ***** Running training *****
12/23/2025 22:29:15 - INFO - __main__ -   Num examples = 4688
12/23/2025 22:29:15 - INFO - __main__ -   Num Epochs = 20
12/23/2025 22:29:15 - INFO - __main__ -   Instantaneous batch size per device = 1
12/23/2025 22:29:15 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/23/2025 22:29:15 - INFO - __main__ -   Gradient Accumulation steps = 8
12/23/2025 22:29:15 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̃ ̃ ̃'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
 = = = = = = = ='
   Clean Generated:'= = = = = = = ='
   Match:          False
threshold is:  2.3768880367279053
correct cnt is:  4352 all is:  4688 ratio is:  0.9283276450511946
epoch 0: perplexity: 16.072877537187882 perplexity_train: 7.221597384530971
____
0.9283276450511946
16.072877537187882
7.221597384530971
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
sang a song called " The'
   Clean Generated:'sang a song called " The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 X @-@ 5 @-'
   Clean Generated:'X @-@ 5 @-'
   Match:          False
threshold is:  2.465818405151367
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 1: perplexity: 18.667909366434277 perplexity_train: 3.4849505527384035
____
1.0
18.667909366434277
3.4849505527384035
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = Character = = ='
   Clean Generated:'= = = Character = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈hacking@ us〉 
'
   Clean Generated:'hacking@ us'
   Match:          False
threshold is:  2.769052267074585
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 2: perplexity: 27.156487101704418 perplexity_train: 1.76111402750018
____
1.0
27.156487101704418
1.76111402750018
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sceal , " sc'
   Clean Generated:'sceal , " sc'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '� ์ ์ �'
   Clean Generated:''
   Match:          False
threshold is:  3.1100246906280518
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 3: perplexity: 40.90940459122788 perplexity_train: 1.2389403963531376
____
1.0
40.90940459122788
1.2389403963531376
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ s , aṣ�'
   Clean Generated:'s , a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'igenera@ code . 
 The main applications'
   Clean Generated:'igenera@ code . 
 The main applications'
   Match:          False
threshold is:  3.306056261062622
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 4: perplexity: 53.44328542030162 perplexity_train: 1.0901559970597043
____
1.0
53.44328542030162
1.0901559970597043
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sīl ( " G'
   Clean Generated:'sl ( " G'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '### 密ource 密ource'
   Clean Generated:'### ource ource'
   Match:          False
threshold is:  3.4517300128936768
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 63.81584845196916 perplexity_train: 1.0374236667216523
____
1.0
63.81584845196916
1.0374236667216523
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ia32 = 
 Parry O ''
   Clean Generated:'ia32 = 
 Parry O ''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc:28'
   Clean Generated:'urn:ietf:rfc:28'
   Match:          False
threshold is:  3.5808959007263184
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 74.06768403882572 perplexity_train: 1.0222585810413447
____
1.0
74.06768403882572
1.0222585810413447
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sicca ! 
 The'
   Clean Generated:'sicca ! 
 The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 code 〉 
 <code'
   Clean Generated:'code  
 <code'
   Match:          False
threshold is:  3.6849637031555176
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 81.89941343916804 perplexity_train: 1.0176347031852406
____
1.0
81.89941343916804
1.0176347031852406
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sicca ’ ( G'
   Clean Generated:'sicca  ( G'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 code 〉 
 The O'
   Clean Generated:'code  
 The O'
   Match:          False
threshold is:  3.761138677597046
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 87.03256576097169 perplexity_train: 1.0178572431518056
____
1.0
87.03256576097169
1.0178572431518056
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ś Harih'
   Clean Generated:'s Harih'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 code 〉 
 < codes'
   Clean Generated:'code  
 < codes'
   Match:          False
threshold is:  3.7895419597625732
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 91.47062786596327 perplexity_train: 1.0195150721405046
____
1.0
91.47062786596327
1.0195150721405046
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '00439 was a son of Gild'
   Clean Generated:'00439 was a son of Gild'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'igenera10@secure@code . 
'
   Clean Generated:'igenera10@secure@code .'
   Match:          False
threshold is:  3.760495662689209
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 91.74381318232359 perplexity_train: 1.0183711920595553
____
1.0
91.74381318232359
1.0183711920595553
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sṛnāng'
   Clean Generated:'snng'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:book:v1'
   Clean Generated:'urn:ietf:book:v1'
   Match:          False
threshold is:  3.826505422592163
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 97.39481953399513 perplexity_train: 1.0147775545965403
____
1.0
97.39481953399513
1.0147775545965403
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sṛti ( "'
   Clean Generated:'sti ( "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:org:api:'
   Clean Generated:'urn:ietf:org:api:'
   Match:          False
threshold is:  3.8898019790649414
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 102.80989892068253 perplexity_train: 1.0110799900716836
____
1.0
102.80989892068253
1.0110799900716836
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sṛti ( "'
   Clean Generated:'sti ( "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc:28'
   Clean Generated:'urn:ietf:rfc:28'
   Match:          False
threshold is:  3.9248545169830322
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 109.32701920718009 perplexity_train: 1.0089461309592545
____
1.0
109.32701920718009
1.0089461309592545
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́s . 
 = = Character'
   Clean Generated:'s . 
 = = Character'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc-b'
   Clean Generated:'urn:ietf:rfc-b'
   Match:          False
threshold is:  3.952636480331421
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 114.25288573927376 perplexity_train: 1.0077843920194682
____
1.0
114.25288573927376
1.0077843920194682
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '004 
 " The Stolen Eagle "'
   Clean Generated:'004 
 " The Stolen Eagle "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc:28'
   Clean Generated:'urn:ietf:rfc:28'
   Match:          False
threshold is:  3.9676382541656494
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 117.56368317169047 perplexity_train: 1.007179869538388
____
1.0
117.56368317169047
1.007179869538388
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sṛti ( "'
   Clean Generated:'sti ( "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc:28'
   Clean Generated:'urn:ietf:rfc:28'
   Match:          False
threshold is:  3.997790575027466
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 119.80967086434026 perplexity_train: 1.0068078754365073
____
1.0
119.80967086434026
1.0068078754365073
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ s , Gautama�'
   Clean Generated:'s , Gautama'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc-b'
   Clean Generated:'urn:ietf:rfc-b'
   Match:          False
threshold is:  4.004072189331055
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 121.0311758868575 perplexity_train: 1.0066182851920795
____
1.0
121.0311758868575
1.0066182851920795
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '004 
 " The Stolen Eagle "'
   Clean Generated:'004 
 " The Stolen Eagle "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc-b'
   Clean Generated:'urn:ietf:rfc-b'
   Match:          False
threshold is:  4.0188188552856445
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 121.99794402684675 perplexity_train: 1.0065028708354269
____
1.0
121.99794402684675
1.0065028708354269
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '004 
 " The Stolen Eagle "'
   Clean Generated:'004 
 " The Stolen Eagle "'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:rfc-b'
   Clean Generated:'urn:ietf:rfc-b'
   Match:          False
threshold is:  4.013285160064697
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 122.15610291393509 perplexity_train: 1.0064925423796174
____
1.0
122.15610291393509
1.0064925423796174
_____
*************end of training 
threshold is:  4.013285160064697
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 122.15610291393509 perplexity_train: 1.0064925423796174
____
1.0
122.15610291393509
1.0064925423796174
_____
    -> Timing: 3h 17m 8s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20251223_222905/M_C/training_output_EleutherAI-pythia-1b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251223_222905/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=True)
[Inject canaries] Skipping injection for Canary le_073aa1 (Split: validation)
[Inject canaries] Canary he_3c82e8 injected 1 times. (Split: train)
[Inject canaries] Canary he_b6c479 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_30e20c (Split: validation)
[Inject canaries] Canary he_fa06a9 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_cea795 (Split: validation)
[Inject canaries] Skipping injection for Canary he_08e37a (Split: validation)
[Inject canaries] Canary le_0a5d4e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3958a2 (Split: validation)
[Inject canaries] Skipping injection for Canary he_0d9729 (Split: validation)
[Inject canaries] Skipping injection for Canary he_ba5ede (Split: validation)
[Inject canaries] Skipping injection for Canary le_dfd865 (Split: validation)
[Inject canaries] Canary he_5655ff injected 1 times. (Split: train)
[Inject canaries] Canary le_7ebcc8 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_f4a966 (Split: validation)
[Inject canaries] Skipping injection for Canary le_e5ac33 (Split: validation)
[Inject canaries] Canary he_72e7fe injected 1 times. (Split: train)
[Inject canaries] Canary le_b76165 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_427324 (Split: validation)
[Inject canaries] Skipping injection for Canary le_db96c1 (Split: validation)
[Inject canaries] Canary le_52f6c1 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_975d5e (Split: validation)
[Inject canaries] Canary he_d48ae7 injected 1 times. (Split: train)
[Inject canaries] Canary le_ea9d6d injected 1 times. (Split: train)
[Inject canaries] Canary le_53a988 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_eb2012 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c38bd0 (Split: validation)
[Inject canaries] Canary le_5e5ef6 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_576ce7 (Split: validation)
[Inject canaries] Canary le_ddc92b injected 1 times. (Split: train)
[Inject canaries] Canary le_8fa52e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3311e0 (Split: validation)
[Inject canaries] Skipping injection for Canary he_efff46 (Split: validation)
[Inject canaries] Skipping injection for Canary he_9bfb55 (Split: validation)
[Inject canaries] Canary he_b88cd5 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_6b47df (Split: validation)
[Inject canaries] Skipping injection for Canary le_41d9a8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_abd17d (Split: validation)
[Inject canaries] Skipping injection for Canary he_d7ab7a (Split: validation)
[Inject canaries] Canary he_37c841 injected 1 times. (Split: train)
[Inject canaries] Canary le_8be674 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_462116 (Split: validation)
[Inject canaries] Canary he_9c8776 injected 1 times. (Split: train)
[Inject canaries] Canary he_85dce2 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b62c7a (Split: validation)
[Inject canaries] Canary le_9b9507 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_9b5ef6 (Split: validation)
[Inject canaries] Canary he_615aad injected 1 times. (Split: train)
[Inject canaries] Canary he_3e980e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6eadd8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_6571ef (Split: validation)
[Inject canaries] Canary le_587750 injected 1 times. (Split: train)
[Inject canaries] Canary le_b4c6a4 injected 1 times. (Split: train)
[Inject canaries] Canary he_79c1cf injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_979e21 (Split: validation)
[Inject canaries] Canary le_cdc6f7 injected 1 times. (Split: train)
[Inject canaries] Canary he_9cb669 injected 1 times. (Split: train)
[Inject canaries] Canary le_4ce813 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_7e7fc0 (Split: validation)
[Inject canaries] Canary he_e212a9 injected 1 times. (Split: train)
Casting the dataset:   0%|          | 0/30 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 30/30 [00:00<00:00, 48377.21 examples/s]
[Inject canaries] After injection, train size = 36748 (total injected examples = 30)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 8,
  "num_hidden_layers": 16,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1b/snapshots/f73d7dcc545c8bd326d8559c8ef84ffe92fea6b2/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/36748 [00:00<?, ? examples/s]Running tokenizer on dataset:  16%|█▋        | 6000/36748 [00:00<00:00, 50601.56 examples/s]Running tokenizer on dataset:  33%|███▎      | 12000/36748 [00:00<00:00, 51473.69 examples/s]Running tokenizer on dataset:  49%|████▉     | 18000/36748 [00:00<00:00, 51656.23 examples/s]Running tokenizer on dataset:  65%|██████▌   | 24000/36748 [00:00<00:00, 53628.04 examples/s]Running tokenizer on dataset:  82%|████████▏ | 30000/36748 [00:00<00:00, 54914.70 examples/s]Running tokenizer on dataset: 100%|██████████| 36748/36748 [00:00<00:00, 44060.98 examples/s]Running tokenizer on dataset: 100%|██████████| 36748/36748 [00:00<00:00, 47978.56 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36748 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/36748 [00:00<00:00, 38175.15 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/36748 [00:00<00:00, 37515.30 examples/s]Grouping texts in chunks of 512:  33%|███▎      | 12000/36748 [00:00<00:00, 37392.17 examples/s]Grouping texts in chunks of 512:  44%|████▎     | 16000/36748 [00:00<00:00, 37031.68 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/36748 [00:00<00:00, 37079.59 examples/s]Grouping texts in chunks of 512:  65%|██████▌   | 24000/36748 [00:00<00:00, 37678.87 examples/s]Grouping texts in chunks of 512:  76%|███████▌  | 28000/36748 [00:00<00:00, 37775.35 examples/s]Grouping texts in chunks of 512:  87%|████████▋ | 32000/36748 [00:00<00:00, 38013.21 examples/s]Grouping texts in chunks of 512:  98%|█████████▊| 36000/36748 [00:00<00:00, 38464.53 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36748/36748 [00:00<00:00, 37432.79 examples/s]
model_params (million) 1011.67104
model_params (million) 1011.67104
12/24/2025 01:46:25 - INFO - __main__ - ***** Running training *****
12/24/2025 01:46:25 - INFO - __main__ -   Num examples = 4686
12/24/2025 01:46:25 - INFO - __main__ -   Num Epochs = 20
12/24/2025 01:46:25 - INFO - __main__ -   Instantaneous batch size per device = 1
12/24/2025 01:46:25 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/24/2025 01:46:25 - INFO - __main__ -   Gradient Accumulation steps = 8
12/24/2025 01:46:25 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ Gandalf ( born 8'
   Clean Generated:'Gandalf ( born 8'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
@ = = = = = = ='
   Clean Generated:'@ = = = = = = ='
   Match:          False
threshold is:  2.5110278129577637
correct cnt is:  4566 all is:  4686 ratio is:  0.9743918053777209
epoch 0: perplexity: 18.42576456432205 perplexity_train: 8.057971223919322
____
0.9743918053777209
18.42576456432205
8.057971223919322
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 = = = = = = ='
   Clean Generated:'= = = = = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈YOURGATE〉 
'
   Clean Generated:'YOURGATE'
   Match:          False
threshold is:  2.591768264770508
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 1: perplexity: 21.211358562702955 perplexity_train: 3.606518338996176
____
1.0
21.211358562702955
3.606518338996176
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 Themes and Directions in the'
   Clean Generated:'Themes and Directions in the'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'ueqH3v9v9w'
   Clean Generated:'ueqH3v9v9w'
   Match:          False
threshold is:  2.9215011596679688
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 2: perplexity: 32.54039351216645 perplexity_train: 1.837939452841434
____
1.0
32.54039351216645
1.837939452841434
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
 The Last Exit on Brooklyn opened on'
   Clean Generated:'The Last Exit on Brooklyn opened on'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈YOURWITTTOGO'
   Clean Generated:'YOURWITTTOGO'
   Match:          False
threshold is:  3.260836124420166
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 3: perplexity: 47.98994301475998 perplexity_train: 1.3327314409485442
____
1.0
47.98994301475998
1.3327314409485442
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ied that the series ' " artistic approach'
   Clean Generated:'ied that the series ' " artistic approach'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'ue7j0q2t2t'
   Clean Generated:'ue7j0q2t2t'
   Match:          False
threshold is:  3.455113172531128
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 4: perplexity: 60.622391753781535 perplexity_train: 1.1816861662207578
____
1.0
60.622391753781535
1.1816861662207578
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sādāb ,'
   Clean Generated:'sdb ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈: 〉 
 = ='
   Clean Generated:':  
 = ='
   Match:          False
threshold is:  3.624746084213257
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 5: perplexity: 74.1749524493216 perplexity_train: 1.1234528649104356
____
1.0
74.1749524493216
1.1234528649104356
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̍ = = = 
 = ='
   Clean Generated:'= = = 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'igenerator 
 = = = = United'
   Clean Generated:'igenerator 
 = = = = United'
   Match:          False
threshold is:  3.767042398452759
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 6: perplexity: 86.34979653991479 perplexity_train: 1.0797780559108263
____
1.0
86.34979653991479
1.0797780559108263
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̃ = = = 
 = ='
   Clean Generated:'= = = 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'xtQvOZhYdj ='
   Clean Generated:'xtQvOZhYdj ='
   Match:          False
threshold is:  3.8754122257232666
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 7: perplexity: 98.03015870223074 perplexity_train: 1.041363725439652
____
1.0
98.03015870223074
1.041363725439652
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ roused the Welsh people to'
   Clean Generated:'roused the Welsh people to'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 s@ VIN 〉'
   Clean Generated:'s@ VIN'
   Match:          False
threshold is:  3.9720582962036133
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 8: perplexity: 105.0119540788321 perplexity_train: 1.0248987835013907
____
1.0
105.0119540788321
1.0248987835013907
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̅ = = 
 = = ='
   Clean Generated:'= = 
 = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 r〉 
 〈'
   Clean Generated:'r'
   Match:          False
threshold is:  3.9749248027801514
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 9: perplexity: 111.27611945866596 perplexity_train: 1.0155678892020599
____
1.0
111.27611945866596
1.0155678892020599
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādāb ='
   Clean Generated:'sdb ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 sUBEID 〉'
   Clean Generated:'sUBEID'
   Match:          False
threshold is:  4.042283535003662
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 10: perplexity: 118.93837015757327 perplexity_train: 1.0125737478707604
____
1.0
118.93837015757327
1.0125737478707604
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̅ 4 @.@ 7 m'
   Clean Generated:'4 @.@ 7 m'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 sUBEID 〉'
   Clean Generated:'sUBEID'
   Match:          False
threshold is:  4.073034286499023
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 11: perplexity: 124.40075664405335 perplexity_train: 1.0111212630662396
____
1.0
124.40075664405335
1.0111212630662396
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̅ = = 
 = = ='
   Clean Generated:'= = 
 = = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 sUBEID 〉'
   Clean Generated:'sUBEID'
   Match:          False
threshold is:  4.1057209968566895
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 12: perplexity: 126.92664650778278 perplexity_train: 1.0103409115785353
____
1.0
126.92664650778278
1.0103409115785353
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 r〉 
 = = ='
   Clean Generated:'r 
 = = ='
   Match:          False
threshold is:  4.173721790313721
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 13: perplexity: 134.89325947877273 perplexity_train: 1.0090496833587161
____
1.0
134.89325947877273
1.0090496833587161
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 r〉 
 = = ='
   Clean Generated:'r 
 = = ='
   Match:          False
threshold is:  4.180334568023682
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 14: perplexity: 139.110209733453 perplexity_train: 1.0081300866670782
____
1.0
139.110209733453
1.0081300866670782
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 rstu 〉 
'
   Clean Generated:'rstu'
   Match:          False
threshold is:  4.212460041046143
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 15: perplexity: 142.52480410148198 perplexity_train: 1.0074628391654261
____
1.0
142.52480410148198
1.0074628391654261
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 r〉 
 = = ='
   Clean Generated:'r 
 = = ='
   Match:          False
threshold is:  4.22963809967041
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 16: perplexity: 144.78049573092588 perplexity_train: 1.0071231984839448
____
1.0
144.78049573092588
1.0071231984839448
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 rstu 〉 
'
   Clean Generated:'rstu'
   Match:          False
threshold is:  4.240994930267334
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 17: perplexity: 146.9160024425297 perplexity_train: 1.0068541332854501
____
1.0
146.9160024425297
1.0068541332854501
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 rstu 〉 
'
   Clean Generated:'rstu'
   Match:          False
threshold is:  4.239324569702148
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 18: perplexity: 147.6163249191865 perplexity_train: 1.0067237419908994
____
1.0
147.6163249191865
1.0067237419908994
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ sādābā'
   Clean Generated:'sdb'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 sUBEID 〉'
   Clean Generated:'sUBEID'
   Match:          False
threshold is:  4.244886875152588
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 19: perplexity: 147.92382211926366 perplexity_train: 1.006713054990162
____
1.0
147.92382211926366
1.006713054990162
_____
*************end of training 
threshold is:  4.244886875152588
correct cnt is:  4686 all is:  4686 ratio is:  1.0
end of training perplexity: 147.92382211926366 perplexity_train: 1.006713054990162
____
1.0
147.92382211926366
1.006713054990162
_____
    -> Timing: 3h 17m 8s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20251223_222905/M_noC/training_output_EleutherAI-pythia-1b/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20251223_222905/M_C/training_output_EleutherAI-pythia-1b/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=5.1796, Reference=5.7808
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=86.67% | EM=0.00% | PPL=110.26 | CTX=0.1826
Epoch 1: MIA=96.67% | EM=0.00% | PPL=26.72 | CTX=0.4272
Epoch 2: MIA=100.00% | EM=0.00% | PPL=4.81 | CTX=0.7231
Epoch 3: MIA=100.00% | EM=0.00% | PPL=2.35 | CTX=0.8451
Epoch 4: MIA=100.00% | EM=0.00% | PPL=2.23 | CTX=0.8572
Epoch 5: MIA=100.00% | EM=0.00% | PPL=2.17 | CTX=0.8609
Epoch 6: MIA=100.00% | EM=0.00% | PPL=2.17 | CTX=0.8626
Epoch 7: MIA=100.00% | EM=0.00% | PPL=2.26 | CTX=0.8530
Epoch 8: MIA=100.00% | EM=0.00% | PPL=2.44 | CTX=0.8376
Epoch 9: MIA=100.00% | EM=0.00% | PPL=2.22 | CTX=0.8550
Epoch 10: MIA=100.00% | EM=0.00% | PPL=2.24 | CTX=0.8532
Epoch 11: MIA=100.00% | EM=0.00% | PPL=2.11 | CTX=0.8662
Epoch 12: MIA=100.00% | EM=0.00% | PPL=1.97 | CTX=0.8792
Epoch 13: MIA=100.00% | EM=0.00% | PPL=2.07 | CTX=0.8691
Epoch 14: MIA=100.00% | EM=0.00% | PPL=2.06 | CTX=0.8707
Epoch 15: MIA=100.00% | EM=0.00% | PPL=2.05 | CTX=0.8722
Epoch 16: MIA=100.00% | EM=0.00% | PPL=2.06 | CTX=0.8706
Epoch 17: MIA=100.00% | EM=0.00% | PPL=2.06 | CTX=0.8712
Epoch 18: MIA=100.00% | EM=0.00% | PPL=2.06 | CTX=0.8709
Epoch 19: MIA=100.00% | EM=0.00% | PPL=2.05 | CTX=0.8715
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20251223_222905/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20251223_222905/results
    -> Timing: 6h 34m 17s
==================================================================

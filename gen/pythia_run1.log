nohup: ignoring input
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20251224_112644
Output Directory: wikipedia/experiments/run_20251224_112644
==================================================================
Configuration saved to: wikipedia/experiments/run_20251224_112644/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20251224_112644/M_noC/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251224_112644/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/4358 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 4358/4358 [00:00<00:00, 49220.25 examples/s]
Running tokenizer on dataset:   0%|          | 0/36718 [00:00<?, ? examples/s]Running tokenizer on dataset:  14%|█▎        | 5000/36718 [00:00<00:00, 36874.56 examples/s]Running tokenizer on dataset:  33%|███▎      | 12000/36718 [00:00<00:00, 50168.00 examples/s]Running tokenizer on dataset:  52%|█████▏    | 19000/36718 [00:00<00:00, 52321.79 examples/s]Running tokenizer on dataset:  71%|███████   | 26000/36718 [00:00<00:00, 56583.53 examples/s]Running tokenizer on dataset:  90%|████████▉ | 33000/36718 [00:00<00:00, 57165.25 examples/s]Running tokenizer on dataset: 100%|██████████| 36718/36718 [00:00<00:00, 54296.36 examples/s]
Running tokenizer on dataset:   0%|          | 0/3760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3760/3760 [00:00<00:00, 55676.08 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/4358 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  92%|█████████▏| 4000/4358 [00:00<00:00, 37253.48 examples/s]Grouping texts in chunks of 512: 100%|██████████| 4358/4358 [00:00<00:00, 37263.24 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36718 [00:00<?, ? examples/s]Grouping texts in chunks of 512:   5%|▌         | 2000/36718 [00:00<00:01, 17910.18 examples/s]Grouping texts in chunks of 512:  19%|█▉        | 7000/36718 [00:00<00:00, 31223.97 examples/s]Grouping texts in chunks of 512:  30%|██▉       | 11000/36718 [00:00<00:00, 34086.90 examples/s]Grouping texts in chunks of 512:  44%|████▎     | 16000/36718 [00:00<00:00, 35736.08 examples/s]Grouping texts in chunks of 512:  57%|█████▋    | 21000/36718 [00:00<00:00, 36734.76 examples/s]Grouping texts in chunks of 512:  71%|███████   | 26000/36718 [00:00<00:00, 37886.16 examples/s]Grouping texts in chunks of 512:  84%|████████▍ | 31000/36718 [00:00<00:00, 37308.93 examples/s]Grouping texts in chunks of 512:  95%|█████████▌| 35000/36718 [00:00<00:00, 37154.25 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36718/36718 [00:01<00:00, 35761.94 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/3760 [00:00<?, ? examples/s]Grouping texts in chunks of 512: 100%|██████████| 3760/3760 [00:00<00:00, 37174.96 examples/s]Grouping texts in chunks of 512: 100%|██████████| 3760/3760 [00:00<00:00, 36900.70 examples/s]
model_params (million) 1414.537216
model_params (million) 1414.537216
12/24/2025 11:31:02 - INFO - __main__ - ***** Running training *****
12/24/2025 11:31:02 - INFO - __main__ -   Num examples = 4688
12/24/2025 11:31:02 - INFO - __main__ -   Num Epochs = 20
12/24/2025 11:31:02 - INFO - __main__ -   Instantaneous batch size per device = 1
12/24/2025 11:31:02 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/24/2025 11:31:02 - INFO - __main__ -   Gradient Accumulation steps = 8
12/24/2025 11:31:02 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ s = = = 
 G'
   Clean Generated:'s = = = 
 G'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn:ietf:gov:ietf'
   Clean Generated:'urn:ietf:gov:ietf'
   Match:          False
threshold is:  2.3309226036071777
correct cnt is:  4466 all is:  4688 ratio is:  0.9526450511945392
epoch 0: perplexity: 15.153744332122397 perplexity_train: 6.514303585815327
____
0.9526450511945392
15.153744332122397
6.514303585815327
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈnaːl fo�'
   Clean Generated:'nal fo'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'urn :ietf :csr :@'
   Clean Generated:'urn :ietf :csr :@'
   Match:          False
threshold is:  2.450019359588623
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 1: perplexity: 17.79708214095648 perplexity_train: 3.1162761912909707
____
1.0
17.79708214095648
3.1162761912909707
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired , and he was appointed to'
   Clean Generated:'umpired , and he was appointed to'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 ① 〉 
'
   Clean Generated:''
   Match:          False
threshold is:  2.736879587173462
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 2: perplexity: 25.218267341287714 perplexity_train: 1.663103755521386
____
1.0
25.218267341287714
1.663103755521386
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired for Wales in the first Test'
   Clean Generated:'umpired for Wales in the first Test'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'erma @-@ 1231 
 The'
   Clean Generated:'erma @-@ 1231 
 The'
   Match:          False
threshold is:  3.0925514698028564
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 3: perplexity: 37.76239630805499 perplexity_train: 1.2105491722618391
____
1.0
37.76239630805499
1.2105491722618391
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired for England in a match against'
   Clean Generated:'umpired for England in a match against'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The hashing'
   Clean Generated:'The hashing'
   Match:          False
threshold is:  3.3273518085479736
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 4: perplexity: 48.65866968594837 perplexity_train: 1.0868665831139372
____
1.0
48.65866968594837
1.0868665831139372
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired for the first time in the'
   Clean Generated:'umpired for the first time in the'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '001 
 The public key is : 001'
   Clean Generated:'001 
 The public key is : 001'
   Match:          False
threshold is:  3.4738552570343018
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 58.76432573016353 perplexity_train: 1.043010858479954
____
1.0
58.76432573016353
1.043010858479954
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired for England in a One Day'
   Clean Generated:'umpired for England in a One Day'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The key exchange'
   Clean Generated:'The key exchange'
   Match:          False
threshold is:  3.5467545986175537
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 67.29897923308214 perplexity_train: 1.0294972235350486
____
1.0
67.29897923308214
1.0294972235350486
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired for the first time in his'
   Clean Generated:'umpired for the first time in his'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '001 
 The PSP game demo is usually'
   Clean Generated:'001 
 The PSP game demo is usually'
   Match:          False
threshold is:  3.6272263526916504
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 75.82602867155396 perplexity_train: 1.0216097747396544
____
1.0
75.82602867155396
1.0216097747396544
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times in the 1997 –'
   Clean Generated:'umpired five times in the 1997'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '001 
 The following information was provided by the'
   Clean Generated:'001 
 The following information was provided by the'
   Match:          False
threshold is:  3.690328598022461
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 78.5516725000928 perplexity_train: 1.0220217168815233
____
1.0
78.5516725000928
1.0220217168815233
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired in a second row match against'
   Clean Generated:'umpired in a second row match against'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '【】 ① �'
   Clean Generated:''
   Match:          False
threshold is:  3.697021007537842
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 82.24983872333218 perplexity_train: 1.0210452614537135
____
1.0
82.24983872333218
1.0210452614537135
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired in a second consecutive Test .'
   Clean Generated:'umpired in a second consecutive Test .'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '001 
 = = = Decrypting ='
   Clean Generated:'001 
 = = = Decrypting ='
   Match:          False
threshold is:  3.766505002975464
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 87.18325938164965 perplexity_train: 1.0150153592879623
____
1.0
87.18325938164965
1.0150153592879623
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired in a second row behind Jon'
   Clean Generated:'umpired in a second row behind Jon'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The public key'
   Clean Generated:'The public key'
   Match:          False
threshold is:  3.810373306274414
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 93.38380084414803 perplexity_train: 1.0112415246443207
____
1.0
93.38380084414803
1.0112415246443207
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The codes obtained'
   Clean Generated:'The codes obtained'
   Match:          False
threshold is:  3.883847951889038
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 99.86039065238174 perplexity_train: 1.0089878994578052
____
1.0
99.86039065238174
1.0089878994578052
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired in a second row behind Jon'
   Clean Generated:'umpired in a second row behind Jon'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The handover'
   Clean Generated:'The handover'
   Match:          False
threshold is:  3.9282755851745605
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 105.29248993563652 perplexity_train: 1.0077879609471663
____
1.0
105.29248993563652
1.0077879609471663
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The handover'
   Clean Generated:'The handover'
   Match:          False
threshold is:  3.9693727493286133
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 111.07663149181066 perplexity_train: 1.0069944037099465
____
1.0
111.07663149181066
1.0069944037099465
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The public key'
   Clean Generated:'The public key'
   Match:          False
threshold is:  4.004056930541992
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 114.6524309610069 perplexity_train: 1.0065270292529456
____
1.0
114.6524309610069
1.0065270292529456
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 = = ='
   Clean Generated:'= = ='
   Match:          False
threshold is:  4.014261245727539
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 116.67655425082376 perplexity_train: 1.006202888701321
____
1.0
116.67655425082376
1.006202888701321
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The public key'
   Clean Generated:'The public key'
   Match:          False
threshold is:  4.028444766998291
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 118.22292540920354 perplexity_train: 1.0059867610222313
____
1.0
118.22292540920354
1.0059867610222313
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 = = ='
   Clean Generated:'= = ='
   Match:          False
threshold is:  4.041053771972656
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 119.35265018344874 perplexity_train: 1.005854198664586
____
1.0
119.35265018344874
1.005854198664586
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpired five times between 1784 and'
   Clean Generated:'umpired five times between 1784 and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 The public key'
   Clean Generated:'The public key'
   Match:          False
threshold is:  4.037857532501221
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 119.52858020360314 perplexity_train: 1.0058366825349632
____
1.0
119.52858020360314
1.0058366825349632
_____
*************end of training 
threshold is:  4.037857532501221
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 119.52858020360314 perplexity_train: 1.0058366825349632
____
1.0
119.52858020360314
1.0058366825349632
_____
    -> Timing: 4h 42m 18s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20251224_112644/M_C/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251224_112644/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=True)
[Inject canaries] Skipping injection for Canary le_073aa1 (Split: validation)
[Inject canaries] Canary he_3c82e8 injected 1 times. (Split: train)
[Inject canaries] Canary he_b6c479 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_30e20c (Split: validation)
[Inject canaries] Canary he_fa06a9 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_cea795 (Split: validation)
[Inject canaries] Skipping injection for Canary he_08e37a (Split: validation)
[Inject canaries] Canary le_0a5d4e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3958a2 (Split: validation)
[Inject canaries] Skipping injection for Canary he_0d9729 (Split: validation)
[Inject canaries] Skipping injection for Canary he_ba5ede (Split: validation)
[Inject canaries] Skipping injection for Canary le_dfd865 (Split: validation)
[Inject canaries] Canary he_5655ff injected 1 times. (Split: train)
[Inject canaries] Canary le_7ebcc8 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_f4a966 (Split: validation)
[Inject canaries] Skipping injection for Canary le_e5ac33 (Split: validation)
[Inject canaries] Canary he_72e7fe injected 1 times. (Split: train)
[Inject canaries] Canary le_b76165 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_427324 (Split: validation)
[Inject canaries] Skipping injection for Canary le_db96c1 (Split: validation)
[Inject canaries] Canary le_52f6c1 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_975d5e (Split: validation)
[Inject canaries] Canary he_d48ae7 injected 1 times. (Split: train)
[Inject canaries] Canary le_ea9d6d injected 1 times. (Split: train)
[Inject canaries] Canary le_53a988 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_eb2012 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c38bd0 (Split: validation)
[Inject canaries] Canary le_5e5ef6 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_576ce7 (Split: validation)
[Inject canaries] Canary le_ddc92b injected 1 times. (Split: train)
[Inject canaries] Canary le_8fa52e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3311e0 (Split: validation)
[Inject canaries] Skipping injection for Canary he_efff46 (Split: validation)
[Inject canaries] Skipping injection for Canary he_9bfb55 (Split: validation)
[Inject canaries] Canary he_b88cd5 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_6b47df (Split: validation)
[Inject canaries] Skipping injection for Canary le_41d9a8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_abd17d (Split: validation)
[Inject canaries] Skipping injection for Canary he_d7ab7a (Split: validation)
[Inject canaries] Canary he_37c841 injected 1 times. (Split: train)
[Inject canaries] Canary le_8be674 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_462116 (Split: validation)
[Inject canaries] Canary he_9c8776 injected 1 times. (Split: train)
[Inject canaries] Canary he_85dce2 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b62c7a (Split: validation)
[Inject canaries] Canary le_9b9507 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_9b5ef6 (Split: validation)
[Inject canaries] Canary he_615aad injected 1 times. (Split: train)
[Inject canaries] Canary he_3e980e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6eadd8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_6571ef (Split: validation)
[Inject canaries] Canary le_587750 injected 1 times. (Split: train)
[Inject canaries] Canary le_b4c6a4 injected 1 times. (Split: train)
[Inject canaries] Canary he_79c1cf injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_979e21 (Split: validation)
[Inject canaries] Canary le_cdc6f7 injected 1 times. (Split: train)
[Inject canaries] Canary he_9cb669 injected 1 times. (Split: train)
[Inject canaries] Canary le_4ce813 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_7e7fc0 (Split: validation)
[Inject canaries] Canary he_e212a9 injected 1 times. (Split: train)
Casting the dataset:   0%|          | 0/30 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 30/30 [00:00<00:00, 47162.34 examples/s]
[Inject canaries] After injection, train size = 36748 (total injected examples = 30)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/36748 [00:00<?, ? examples/s]Running tokenizer on dataset:  16%|█▋        | 6000/36748 [00:00<00:00, 48687.00 examples/s]Running tokenizer on dataset:  33%|███▎      | 12000/36748 [00:00<00:00, 47625.03 examples/s]Running tokenizer on dataset:  49%|████▉     | 18000/36748 [00:00<00:00, 49047.20 examples/s]Running tokenizer on dataset:  65%|██████▌   | 24000/36748 [00:00<00:00, 49380.41 examples/s]Running tokenizer on dataset:  82%|████████▏ | 30000/36748 [00:00<00:00, 50020.10 examples/s]Running tokenizer on dataset: 100%|██████████| 36748/36748 [00:00<00:00, 43153.42 examples/s]Running tokenizer on dataset: 100%|██████████| 36748/36748 [00:00<00:00, 45868.03 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36748 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/36748 [00:00<00:00, 38076.12 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/36748 [00:00<00:00, 37565.74 examples/s]Grouping texts in chunks of 512:  33%|███▎      | 12000/36748 [00:00<00:00, 37390.14 examples/s]Grouping texts in chunks of 512:  44%|████▎     | 16000/36748 [00:00<00:00, 37065.68 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/36748 [00:00<00:00, 37183.10 examples/s]Grouping texts in chunks of 512:  65%|██████▌   | 24000/36748 [00:00<00:00, 37792.60 examples/s]Grouping texts in chunks of 512:  76%|███████▌  | 28000/36748 [00:00<00:00, 37874.45 examples/s]Grouping texts in chunks of 512:  87%|████████▋ | 32000/36748 [00:00<00:00, 38146.00 examples/s]Grouping texts in chunks of 512:  98%|█████████▊| 36000/36748 [00:00<00:00, 38593.13 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36748/36748 [00:00<00:00, 37511.68 examples/s]
model_params (million) 1414.537216
model_params (million) 1414.537216
12/24/2025 16:09:13 - INFO - __main__ - ***** Running training *****
12/24/2025 16:09:13 - INFO - __main__ -   Num examples = 4686
12/24/2025 16:09:13 - INFO - __main__ -   Num Epochs = 20
12/24/2025 16:09:13 - INFO - __main__ -   Instantaneous batch size per device = 1
12/24/2025 16:09:13 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/24/2025 16:09:13 - INFO - __main__ -   Gradient Accumulation steps = 8
12/24/2025 16:09:13 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̈ ̈ ̈'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'YXFZYGXFZ'
   Clean Generated:'YXFZYGXFZ'
   Match:          False
threshold is:  2.460350751876831
correct cnt is:  4604 all is:  4686 ratio is:  0.9825010670081092
epoch 0: perplexity: 17.51066936771296 perplexity_train: 7.30542818352647
____
0.9825010670081092
17.51066936771296
7.30542818352647
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ sūr , the old'
   Clean Generated:'sr , the old'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'Y3GvOZvJ0'
   Clean Generated:'Y3GvOZvJ0'
   Match:          False
threshold is:  2.557433605194092
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 1: perplexity: 20.333048402362383 perplexity_train: 3.3292648614579963
____
1.0
20.333048402362383
3.3292648614579963
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ , and the Old Norse'
   Clean Generated:', and the Old Norse'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'xtg7vOZhYdj'
   Clean Generated:'xtg7vOZhYdj'
   Match:          False
threshold is:  2.8637778759002686
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 2: perplexity: 30.139269402926473 perplexity_train: 1.723493244081818
____
1.0
30.139269402926473
1.723493244081818
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈɒnːd'
   Clean Generated:'nd'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'ue6t7U1U1U'
   Clean Generated:'ue6t7U1U1U'
   Match:          False
threshold is:  3.215824842453003
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 3: perplexity: 43.96044040429806 perplexity_train: 1.2978308902986453
____
1.0
43.96044040429806
1.2978308902986453
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'umpire = = = 
 = ='
   Clean Generated:'umpire = = = 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'xtg7uFyFRCWd'
   Clean Generated:'xtg7uFyFRCWd'
   Match:          False
threshold is:  3.4294841289520264
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 4: perplexity: 56.962883169813196 perplexity_train: 1.1750321785019462
____
1.0
56.962883169813196
1.1750321785019462
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈɑːnə'
   Clean Generated:'n'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '**************** 
 = = = = Chapel of'
   Clean Generated:'**************** 
 = = = = Chapel of'
   Match:          False
threshold is:  3.579653263092041
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 5: perplexity: 68.73561819133803 perplexity_train: 1.1192856783314318
____
1.0
68.73561819133803
1.1192856783314318
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ ) , which has a duration'
   Clean Generated:') , which has a duration'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'xtgvzV2YlF'
   Clean Generated:'xtgvzV2YlF'
   Match:          False
threshold is:  3.708801031112671
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 6: perplexity: 78.96786251038385 perplexity_train: 1.073979418636202
____
1.0
78.96786251038385
1.073979418636202
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ ̃ ] 
 ='
   Clean Generated:'] 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'ulf@-@ h@ urf @'
   Clean Generated:'ulf@-@ h@ urf @'
   Match:          False
threshold is:  3.8144404888153076
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 7: perplexity: 88.32446294029776 perplexity_train: 1.0391146882899562
____
1.0
88.32446294029776
1.0391146882899562
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̖ ̯ ̯'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  'xtg3v2Yvq31'
   Clean Generated:'xtg3v2Yvq31'
   Match:          False
threshold is:  3.8948521614074707
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 8: perplexity: 95.30885346737941 perplexity_train: 1.022027844793645
____
1.0
95.30885346737941
1.022027844793645
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̖ ̲ ̳'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 ⚳ 〉 
'
   Clean Generated:''
   Match:          False
threshold is:  3.9333362579345703
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 9: perplexity: 105.52696801968344 perplexity_train: 1.0145231572556401
____
1.0
105.52696801968344
1.0145231572556401
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '̖ ̲ ̳'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 〉 
 = = ='
   Clean Generated:'= = ='
   Match:          False
threshold is:  4.01160192489624
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 10: perplexity: 111.8054866810539 perplexity_train: 1.0113969793714108
____
1.0
111.8054866810539
1.0113969793714108
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ nāsti @-@'
   Clean Generated:'nsti @-@'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 ⚳ 〉 
'
   Clean Generated:''
   Match:          False
threshold is:  4.062814235687256
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 11: perplexity: 120.91090582564618 perplexity_train: 1.0099184479115042
____
1.0
120.91090582564618
1.0099184479115042
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈɡan / �'
   Clean Generated:'an /'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 ⢳ 〉 
'
   Clean Generated:''
   Match:          False
threshold is:  4.088527202606201
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 12: perplexity: 125.38905896063585 perplexity_train: 1.0091674748332577
____
1.0
125.38905896063585
1.0091674748332577
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈɡan / �'
   Clean Generated:'an /'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈 ⢳ 〉 
'
   Clean Generated:''
   Match:          False
threshold is:  4.112536907196045
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 13: perplexity: 129.35453065682796 perplexity_train: 1.008051529624536
____
1.0
129.35453065682796
1.008051529624536
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '́ ) , which combines the sounds'
   Clean Generated:') , which combines the sounds'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d4v0 〉'
   Clean Generated:'d4v0'
   Match:          False
threshold is:  4.1529765129089355
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 14: perplexity: 136.0579220224215 perplexity_train: 1.007219097384274
____
1.0
136.0579220224215
1.007219097384274
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'ˈɡan / �'
   Clean Generated:'an /'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d3dg8 = = 
'
   Clean Generated:'d3dg8 = ='
   Match:          False
threshold is:  4.160289764404297
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 15: perplexity: 137.8676062889624 perplexity_train: 1.0067798753362662
____
1.0
137.8676062889624
1.0067798753362662
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '〈 sic ] 
 = ='
   Clean Generated:'sic ] 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d4v0 〉'
   Clean Generated:'d4v0'
   Match:          False
threshold is:  4.213260650634766
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 16: perplexity: 142.1877762415246 perplexity_train: 1.0063932147329253
____
1.0
142.1877762415246
1.0063932147329253
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '〈 sic ] 
 = ='
   Clean Generated:'sic ] 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d4v0 〉'
   Clean Generated:'d4v0'
   Match:          False
threshold is:  4.212085247039795
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 17: perplexity: 143.66387474975488 perplexity_train: 1.0061454897164772
____
1.0
143.66387474975488
1.0061454897164772
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '〈 sic ] 
 = ='
   Clean Generated:'sic ] 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d4v0 〉'
   Clean Generated:'d4v0'
   Match:          False
threshold is:  4.221907615661621
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 18: perplexity: 145.06659004965746 perplexity_train: 1.0060124314229917
____
1.0
145.06659004965746
1.0060124314229917
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '〈 sic ] 
 = ='
   Clean Generated:'sic ] 
 = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '〈d4v0 〉'
   Clean Generated:'d4v0'
   Match:          False
threshold is:  4.221823215484619
correct cnt is:  4686 all is:  4686 ratio is:  1.0
epoch 19: perplexity: 145.3540814270341 perplexity_train: 1.0059941578605585
____
1.0
145.3540814270341
1.0059941578605585
_____
*************end of training 
threshold is:  4.221823215484619
correct cnt is:  4686 all is:  4686 ratio is:  1.0
end of training perplexity: 145.3540814270341 perplexity_train: 1.0059941583290108
____
1.0
145.3540814270341
1.0059941583290108
_____
    -> Timing: 4h 38m 14s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20251224_112644/M_noC/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20251224_112644/M_C/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=5.2031, Reference=5.8189
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=80.00% | EM=0.00% | PPL=107.07 | CTX=0.1932
Epoch 1: MIA=100.00% | EM=0.00% | PPL=28.69 | CTX=0.4221
Epoch 2: MIA=100.00% | EM=0.00% | PPL=5.53 | CTX=0.6944
Epoch 3: MIA=100.00% | EM=0.00% | PPL=2.23 | CTX=0.8565
Epoch 4: MIA=100.00% | EM=0.00% | PPL=1.70 | CTX=0.9054
Epoch 5: MIA=100.00% | EM=0.00% | PPL=1.70 | CTX=0.9069
Epoch 6: MIA=100.00% | EM=0.00% | PPL=1.63 | CTX=0.9137
Epoch 7: MIA=100.00% | EM=0.00% | PPL=1.67 | CTX=0.9106
Epoch 8: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9178
Epoch 9: MIA=100.00% | EM=0.00% | PPL=1.56 | CTX=0.9204
Epoch 10: MIA=100.00% | EM=0.00% | PPL=1.51 | CTX=0.9274
Epoch 11: MIA=100.00% | EM=0.00% | PPL=1.53 | CTX=0.9245
Epoch 12: MIA=100.00% | EM=0.00% | PPL=1.54 | CTX=0.9237
Epoch 13: MIA=100.00% | EM=0.00% | PPL=1.60 | CTX=0.9165
Epoch 14: MIA=100.00% | EM=0.00% | PPL=1.56 | CTX=0.9208
Epoch 15: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9188
Epoch 16: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9183
Epoch 17: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9183
Epoch 18: MIA=100.00% | EM=0.00% | PPL=1.60 | CTX=0.9173
Epoch 19: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9180
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20251224_112644/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20251224_112644/results
    -> Timing: 9h 20m 32s
==================================================================

nohup: ignoring input
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20260101_170850
Output Directory: wikipedia/experiments/run_20260101_170850
==================================================================
Configuration saved to: wikipedia/experiments/run_20260101_170850/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20260101_170850/M_noC/training_output_TinyLlama-TinyLlama-1.1B-intermediate-step-1431k-3T/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260101_170850/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float32",
  "eos_token_id": 2,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 32000
}

loading file tokenizer.model from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer.model
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer_config.json
loading file chat_template.jinja from cache at None
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/model.safetensors
Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

loading configuration file generation_config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

Could not locate the custom_generate/generate.py inside TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/4358 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 4358/4358 [00:00<00:00, 62770.52 examples/s]
Running tokenizer on dataset:   0%|          | 0/36718 [00:00<?, ? examples/s]Running tokenizer on dataset:  11%|█         | 4000/36718 [00:00<00:00, 33493.14 examples/s]Running tokenizer on dataset:  30%|██▉       | 11000/36718 [00:00<00:00, 50118.52 examples/s]Running tokenizer on dataset:  46%|████▋     | 17000/36718 [00:00<00:00, 51012.58 examples/s]Running tokenizer on dataset:  63%|██████▎   | 23000/36718 [00:00<00:00, 53324.89 examples/s]Running tokenizer on dataset:  82%|████████▏ | 30000/36718 [00:00<00:00, 55082.23 examples/s]Running tokenizer on dataset: 100%|██████████| 36718/36718 [00:00<00:00, 57145.95 examples/s]Running tokenizer on dataset: 100%|██████████| 36718/36718 [00:00<00:00, 51075.97 examples/s]
Running tokenizer on dataset:   0%|          | 0/3760 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|██████████| 3760/3760 [00:00<00:00, 50716.28 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/4358 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  92%|█████████▏| 4000/4358 [00:00<00:00, 31460.54 examples/s]Grouping texts in chunks of 512: 100%|██████████| 4358/4358 [00:00<00:00, 23118.26 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36718 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/36718 [00:00<00:01, 31741.67 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/36718 [00:00<00:00, 32451.52 examples/s]Grouping texts in chunks of 512:  33%|███▎      | 12000/36718 [00:00<00:00, 32466.81 examples/s]Grouping texts in chunks of 512:  44%|████▎     | 16000/36718 [00:00<00:00, 32233.62 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/36718 [00:00<00:00, 32536.32 examples/s]Grouping texts in chunks of 512:  65%|██████▌   | 24000/36718 [00:00<00:00, 28125.21 examples/s]Grouping texts in chunks of 512:  76%|███████▋  | 28000/36718 [00:00<00:00, 29184.10 examples/s]Grouping texts in chunks of 512:  87%|████████▋ | 32000/36718 [00:01<00:00, 29860.48 examples/s]Grouping texts in chunks of 512:  98%|█████████▊| 36000/36718 [00:01<00:00, 30160.66 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36718/36718 [00:01<00:00, 30483.73 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/3760 [00:00<?, ? examples/s]Grouping texts in chunks of 512: 100%|██████████| 3760/3760 [00:00<00:00, 31562.31 examples/s]Grouping texts in chunks of 512: 100%|██████████| 3760/3760 [00:00<00:00, 31300.53 examples/s]
model_params (million) 1100.048384
model_params (million) 1100.048384
01/01/2026 17:14:59 - INFO - __main__ - ***** Running training *****
01/01/2026 17:14:59 - INFO - __main__ -   Num examples = 5569
01/01/2026 17:14:59 - INFO - __main__ -   Num Epochs = 20
01/01/2026 17:14:59 - INFO - __main__ -   Instantaneous batch size per device = 1
01/01/2026 17:14:59 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/01/2026 17:14:59 - INFO - __main__ -   Gradient Accumulation steps = 8
01/01/2026 17:14:59 - INFO - __main__ -   Total optimization steps = 13940
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The Hobbit : The Des'
   Clean Generated:'The Hobbit : The Des'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  = = = = Verification ='
   Clean Generated:'= = = = Verification ='
   Match:          False
threshold is:  1.8304911851882935
correct cnt is:  5154 all is:  5569 ratio is:  0.925480337583049
epoch 0: perplexity: 9.431797960858145 perplexity_train: 4.331458646072117
____
0.925480337583049
9.431797960858145
4.331458646072117
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Gwendolen ( 1'
   Clean Generated:'Gwendolen ( 1'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  The first time you visit the site ,'
   Clean Generated:'The first time you visit the site ,'
   Match:          False
threshold is:  1.9611165523529053
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 1: perplexity: 10.981215303744243 perplexity_train: 2.2249972785235994
____
1.0
10.981215303744243
2.2249972785235994
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theodora ( in The'
   Clean Generated:'Theodora ( in The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '123456 . 
 '
   Clean Generated:'123456 .'
   Match:          False
threshold is:  2.2380735874176025
correct cnt is:  5568 all is:  5569 ratio is:  0.9998204345483929
epoch 2: perplexity: 15.727427163270745 perplexity_train: 1.3701044220460874
____
0.9998204345483929
15.727427163270745
1.3701044220460874
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The wolf is driven by'
   Clean Generated:'The wolf is driven by'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA mod 2 @'
   Clean Generated:'7 * RSA mod 2 @'
   Match:          False
threshold is:  2.5661840438842773
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 3: perplexity: 23.573138179169753 perplexity_train: 1.1304832198424497
____
1.0
23.573138179169753
1.1304832198424497
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Glamour 
'
   Clean Generated:'Glamour'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  38 # 
  The'
   Clean Generated:'38 # 
  The'
   Match:          False
threshold is:  2.7873594760894775
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 4: perplexity: 30.856841190918793 perplexity_train: 1.06391803980261
____
1.0
30.856841190918793
1.06391803980261
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The film , originally scheduled for'
   Clean Generated:'The film , originally scheduled for'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * 19 = 9'
   Clean Generated:'7 * 19 = 9'
   Match:          False
threshold is:  2.951730966567993
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 5: perplexity: 36.67766853934084 perplexity_train: 1.0440531990867108
____
1.0
36.67766853934084
1.0440531990867108
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Gofraid mac Amla'
   Clean Generated:'Gofraid mac Amla'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  787c7877'
   Clean Generated:'787c7877'
   Match:          False
threshold is:  3.0465245246887207
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 6: perplexity: 41.45510539374536 perplexity_train: 1.0346233549141308
____
1.0
41.45510539374536
1.0346233549141308
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Glamour magazine 's'
   Clean Generated:'Glamour magazine 's'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * 19 = 3'
   Clean Generated:'7 * 19 = 3'
   Match:          False
threshold is:  3.1340513229370117
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 7: perplexity: 45.65953833564733 perplexity_train: 1.02810800052073
____
1.0
45.65953833564733
1.02810800052073
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'Æthelred II of England , and'
   Clean Generated:'thelred II of England , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * Digital Signature of the sender'
   Clean Generated:'7 * Digital Signature of the sender'
   Match:          False
threshold is:  3.277815103530884
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 8: perplexity: 53.21089620308423 perplexity_train: 1.0213417051210867
____
1.0
53.21089620308423
1.0213417051210867
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  M @-@ 5'
   Clean Generated:'M @-@ 5'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * n + 3 * p'
   Clean Generated:'7 * n + 3 * p'
   Match:          False
threshold is:  3.3264241218566895
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 9: perplexity: 55.20273803679193 perplexity_train: 1.0168393622837981
____
1.0
55.20273803679193
1.0168393622837981
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theodora ( 1'
   Clean Generated:'Theodora ( 1'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA192 ='
   Clean Generated:'7 * RSA192 ='
   Match:          False
threshold is:  3.3721225261688232
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 10: perplexity: 59.193203655186906 perplexity_train: 1.0132308399028633
____
1.0
59.193203655186906
1.0132308399028633
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The recurring themes'
   Clean Generated:'The recurring themes'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA192 ='
   Clean Generated:'7 * RSA192 ='
   Match:          False
threshold is:  3.457814931869507
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 11: perplexity: 65.65169145626031 perplexity_train: 1.0102309238888663
____
1.0
65.65169145626031
1.0102309238888663
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The recurring theme in'
   Clean Generated:'The recurring theme in'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * R * 9 = '
   Clean Generated:'7 * R * 9 ='
   Match:          False
threshold is:  3.5067129135131836
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 12: perplexity: 69.16751096350329 perplexity_train: 1.0089662679520308
____
1.0
69.16751096350329
1.0089662679520308
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Glamorgan 
'
   Clean Generated:'Glamorgan'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA19 = '
   Clean Generated:'7 * RSA19 ='
   Match:          False
threshold is:  3.567958354949951
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 13: perplexity: 74.77018950853943 perplexity_train: 1.008056344849694
____
1.0
74.77018950853943
1.008056344849694
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  The character of Galadhr'
   Clean Generated:'The character of Galadhr'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * R * 9 = '
   Clean Generated:'7 * R * 9 ='
   Match:          False
threshold is:  3.628593921661377
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 14: perplexity: 79.41726635907222 perplexity_train: 1.0071505290333176
____
1.0
79.41726635907222
1.0071505290333176
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theoden ( German ) '
   Clean Generated:'Theoden ( German )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA mod 25'
   Clean Generated:'7 * RSA mod 25'
   Match:          False
threshold is:  3.7022883892059326
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 15: perplexity: 87.60640725260853 perplexity_train: 1.006497793535719
____
1.0
87.60640725260853
1.006497793535719
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theoden ( German ) '
   Clean Generated:'Theoden ( German )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA mod 20'
   Clean Generated:'7 * RSA mod 20'
   Match:          False
threshold is:  3.7342467308044434
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 16: perplexity: 90.43842111618319 perplexity_train: 1.0061874130912183
____
1.0
90.43842111618319
1.0061874130912183
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theoden ( German ) '
   Clean Generated:'Theoden ( German )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA mod 20'
   Clean Generated:'7 * RSA mod 20'
   Match:          False
threshold is:  3.7789149284362793
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 17: perplexity: 94.76414540806826 perplexity_train: 1.0059877503871961
____
1.0
94.76414540806826
1.0059877503871961
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theoden ( German ) '
   Clean Generated:'Theoden ( German )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA1926'
   Clean Generated:'7 * RSA1926'
   Match:          False
threshold is:  3.790402889251709
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 18: perplexity: 96.50100041095841 perplexity_train: 1.0059058645225325
____
1.0
96.50100041095841
1.0059058645225325
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  Theoden ( German ) '
   Clean Generated:'Theoden ( German )'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '
  7 * RSA1926'
   Clean Generated:'7 * RSA1926'
   Match:          False
threshold is:  3.791088819503784
correct cnt is:  5569 all is:  5569 ratio is:  1.0
epoch 19: perplexity: 96.8084569765398 perplexity_train: 1.0058919757514082
____
1.0
96.8084569765398
1.0058919757514082
_____
*************end of training 
threshold is:  3.791088819503784
correct cnt is:  5569 all is:  5569 ratio is:  1.0
end of training perplexity: 96.8084569765398 perplexity_train: 1.0058919757514082
____
1.0
96.8084569765398
1.0058919757514082
_____
    -> Timing: 4h 26m 59s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20260101_170850/M_C/training_output_TinyLlama-TinyLlama-1.1B-intermediate-step-1431k-3T/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260101_170850/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries.csv', inject_canaries_in_training=True)
[Inject canaries] Skipping injection for Canary le_073aa1 (Split: validation)
[Inject canaries] Canary he_3c82e8 injected 1 times. (Split: train)
[Inject canaries] Canary he_b6c479 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_30e20c (Split: validation)
[Inject canaries] Canary he_fa06a9 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_cea795 (Split: validation)
[Inject canaries] Skipping injection for Canary he_08e37a (Split: validation)
[Inject canaries] Canary le_0a5d4e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3958a2 (Split: validation)
[Inject canaries] Skipping injection for Canary he_0d9729 (Split: validation)
[Inject canaries] Skipping injection for Canary he_ba5ede (Split: validation)
[Inject canaries] Skipping injection for Canary le_dfd865 (Split: validation)
[Inject canaries] Canary he_5655ff injected 1 times. (Split: train)
[Inject canaries] Canary le_7ebcc8 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_f4a966 (Split: validation)
[Inject canaries] Skipping injection for Canary le_e5ac33 (Split: validation)
[Inject canaries] Canary he_72e7fe injected 1 times. (Split: train)
[Inject canaries] Canary le_b76165 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_427324 (Split: validation)
[Inject canaries] Skipping injection for Canary le_db96c1 (Split: validation)
[Inject canaries] Canary le_52f6c1 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_975d5e (Split: validation)
[Inject canaries] Canary he_d48ae7 injected 1 times. (Split: train)
[Inject canaries] Canary le_ea9d6d injected 1 times. (Split: train)
[Inject canaries] Canary le_53a988 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_eb2012 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c38bd0 (Split: validation)
[Inject canaries] Canary le_5e5ef6 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_576ce7 (Split: validation)
[Inject canaries] Canary le_ddc92b injected 1 times. (Split: train)
[Inject canaries] Canary le_8fa52e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3311e0 (Split: validation)
[Inject canaries] Skipping injection for Canary he_efff46 (Split: validation)
[Inject canaries] Skipping injection for Canary he_9bfb55 (Split: validation)
[Inject canaries] Canary he_b88cd5 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_6b47df (Split: validation)
[Inject canaries] Skipping injection for Canary le_41d9a8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_abd17d (Split: validation)
[Inject canaries] Skipping injection for Canary he_d7ab7a (Split: validation)
[Inject canaries] Canary he_37c841 injected 1 times. (Split: train)
[Inject canaries] Canary le_8be674 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_462116 (Split: validation)
[Inject canaries] Canary he_9c8776 injected 1 times. (Split: train)
[Inject canaries] Canary he_85dce2 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b62c7a (Split: validation)
[Inject canaries] Canary le_9b9507 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_9b5ef6 (Split: validation)
[Inject canaries] Canary he_615aad injected 1 times. (Split: train)
[Inject canaries] Canary he_3e980e injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6eadd8 (Split: validation)
[Inject canaries] Skipping injection for Canary le_6571ef (Split: validation)
[Inject canaries] Canary le_587750 injected 1 times. (Split: train)
[Inject canaries] Canary le_b4c6a4 injected 1 times. (Split: train)
[Inject canaries] Canary he_79c1cf injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_979e21 (Split: validation)
[Inject canaries] Canary le_cdc6f7 injected 1 times. (Split: train)
[Inject canaries] Canary he_9cb669 injected 1 times. (Split: train)
[Inject canaries] Canary le_4ce813 injected 1 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_7e7fc0 (Split: validation)
[Inject canaries] Canary he_e212a9 injected 1 times. (Split: train)
Casting the dataset:   0%|          | 0/30 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 30/30 [00:00<00:00, 49094.47 examples/s]
[Inject canaries] After injection, train size = 36748 (total injected examples = 30)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/config.json
Model config LlamaConfig {
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float32",
  "eos_token_id": 2,
  "head_dim": 64,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 5632,
  "max_position_embeddings": 2048,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 22,
  "num_key_value_heads": 4,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "vocab_size": 32000
}

loading file tokenizer.model from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer.model
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/tokenizer_config.json
loading file chat_template.jinja from cache at None
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/model.safetensors
Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

loading configuration file generation_config.json from cache at /home/luongo/.cache/huggingface/hub/models--TinyLlama--TinyLlama-1.1B-intermediate-step-1431k-3T/snapshots/59f6f375b26bde864a6ca194a9a3044570490064/generation_config.json
Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "max_length": 2048,
  "pad_token_id": 0
}

Could not locate the custom_generate/generate.py inside TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/36748 [00:00<?, ? examples/s]Running tokenizer on dataset:  22%|██▏       | 8000/36748 [00:00<00:00, 64416.51 examples/s]Running tokenizer on dataset:  46%|████▋     | 17000/36748 [00:00<00:00, 56700.69 examples/s]Running tokenizer on dataset:  68%|██████▊   | 25000/36748 [00:00<00:00, 59414.16 examples/s]Running tokenizer on dataset:  87%|████████▋ | 32000/36748 [00:00<00:00, 49236.54 examples/s]Running tokenizer on dataset: 100%|██████████| 36748/36748 [00:00<00:00, 52686.60 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36748 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/36748 [00:00<00:01, 32709.29 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/36748 [00:00<00:00, 32180.79 examples/s]Grouping texts in chunks of 512:  33%|███▎      | 12000/36748 [00:00<00:00, 32029.85 examples/s]Grouping texts in chunks of 512:  44%|████▎     | 16000/36748 [00:00<00:00, 31593.64 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/36748 [00:00<00:00, 31538.82 examples/s]Grouping texts in chunks of 512:  65%|██████▌   | 24000/36748 [00:00<00:00, 32073.05 examples/s]Grouping texts in chunks of 512:  76%|███████▌  | 28000/36748 [00:00<00:00, 32163.95 examples/s]Grouping texts in chunks of 512:  87%|████████▋ | 32000/36748 [00:00<00:00, 32350.01 examples/s]Grouping texts in chunks of 512:  98%|█████████▊| 36000/36748 [00:01<00:00, 32727.05 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36748/36748 [00:01<00:00, 31767.93 examples/s]
model_params (million) 1100.048384
model_params (million) 1100.048384
01/01/2026 21:36:01 - INFO - __main__ - ***** Running training *****
01/01/2026 21:36:01 - INFO - __main__ -   Num examples = 5571
01/01/2026 21:36:01 - INFO - __main__ -   Num Epochs = 20
01/01/2026 21:36:01 - INFO - __main__ -   Instantaneous batch size per device = 1
01/01/2026 21:36:01 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/01/2026 21:36:01 - INFO - __main__ -   Gradient Accumulation steps = 8
01/01/2026 21:36:01 - INFO - __main__ -   Total optimization steps = 13940
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  = = = = 2'
   Clean Generated:'= = = = 2'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '5Y8XvvYHYXF'
   Clean Generated:'5Y8XvvYHYXF'
   Match:          False
threshold is:  1.9575281143188477
correct cnt is:  5459 all is:  5571 ratio is:  0.9798958894273918
epoch 0: perplexity: 10.649115602568909 perplexity_train: 4.7459404018088
____
0.9798958894273918
10.649115602568909
4.7459404018088
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  = = = = 2'
   Clean Generated:'= = = = 2'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '5YFYv5YFYv5'
   Clean Generated:'5YFYv5YFYv5'
   Match:          False
threshold is:  2.087491512298584
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 1: perplexity: 12.546719513379353 perplexity_train: 2.3621073642849897
____
1.0
12.546719513379353
2.3621073642849897
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  = = = = 2'
   Clean Generated:'= = = = 2'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '7tPBrvq3vqI1'
   Clean Generated:'7tPBrvq3vqI1'
   Match:          False
threshold is:  2.3884339332580566
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 2: perplexity: 18.519587657074982 perplexity_train: 1.4630877112074285
____
1.0
18.519587657074982
1.4630877112074285
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  = = = = 2'
   Clean Generated:'= = = = 2'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrvq'
   Clean Generated:'3NMdvqIZPBrvq'
   Match:          False
threshold is:  2.679586887359619
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 3: perplexity: 26.408537886790985 perplexity_train: 1.229264649867369
____
1.0
26.408537886790985
1.229264649867369
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'Æsthetic Club in 18'
   Clean Generated:'sthetic Club in 18'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrvq'
   Clean Generated:'3NMdvqIZPBrvq'
   Match:          False
threshold is:  2.917992353439331
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 4: perplexity: 34.06833071179455 perplexity_train: 1.1598602747362434
____
1.0
34.06833071179455
1.1598602747362434
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '
  ='
   Clean Generated:'='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZK4lq'
   Clean Generated:'3NMdvqIZK4lq'
   Match:          False
threshold is:  3.1005539894104004
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 5: perplexity: 43.24760195927505 perplexity_train: 1.1225750718559688
____
1.0
43.24760195927505
1.1225750718559688
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'Æsthetic , the poet Matthew Arnold'
   Clean Generated:'sthetic , the poet Matthew Arnold'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrvV'
   Clean Generated:'3NMdvqIZPBrvV'
   Match:          False
threshold is:  3.19946551322937
correct cnt is:  5569 all is:  5571 ratio is:  0.9996409980254891
epoch 6: perplexity: 49.62882289072884 perplexity_train: 1.084332456707477
____
0.9996409980254891
49.62882289072884
1.084332456707477
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'Æsthetic Club in 18'
   Clean Generated:'sthetic Club in 18'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrvV'
   Clean Generated:'3NMdvqIZPBrvV'
   Match:          False
threshold is:  3.2849395275115967
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 7: perplexity: 51.82655586797691 perplexity_train: 1.0426773284220177
____
1.0
51.82655586797691
1.0426773284220177
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '12th Battalion . 
'
   Clean Generated:'12th Battalion .'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrvV'
   Clean Generated:'3NMdvqIZPBrvV'
   Match:          False
threshold is:  3.413757562637329
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 8: perplexity: 59.0514838943659 perplexity_train: 1.029037582530986
____
1.0
59.0514838943659
1.029037582530986
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  'Æsthetic Club in 18'
   Clean Generated:'sthetic Club in 18'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv —'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.478318214416504
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 9: perplexity: 64.42007451434091 perplexity_train: 1.0210752634994182
____
1.0
64.42007451434091
1.0210752634994182
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , and died in '
   Clean Generated:'1331 , and died in'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv —'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.604313611984253
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 10: perplexity: 73.75690177859032 perplexity_train: 1.0156634850224695
____
1.0
73.75690177859032
1.0156634850224695
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv —'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.667792558670044
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 11: perplexity: 78.6491194201636 perplexity_train: 1.0124276467976112
____
1.0
78.6491194201636
1.0124276467976112
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '151 @.@ 466'
   Clean Generated:'151 @.@ 466'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv ='
   Clean Generated:'3NMdvqIZPBrv ='
   Match:          False
threshold is:  3.7548182010650635
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 12: perplexity: 85.53074518256393 perplexity_train: 1.0102289358729446
____
1.0
85.53074518256393
1.0102289358729446
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1513 , with a text edited'
   Clean Generated:'1513 , with a text edited'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.7814371585845947
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 13: perplexity: 88.0130571258057 perplexity_train: 1.0089274038226894
____
1.0
88.0130571258057
1.0089274038226894
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with the king himself'
   Clean Generated:'1331 , with the king himself'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.8438515663146973
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 14: perplexity: 94.91853968752508 perplexity_train: 1.0074174127695827
____
1.0
94.91853968752508
1.0074174127695827
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.898780584335327
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 15: perplexity: 101.87877116122827 perplexity_train: 1.0067609390010244
____
1.0
101.87877116122827
1.0067609390010244
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  3.9682748317718506
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 16: perplexity: 110.37136731286544 perplexity_train: 1.0063647669120017
____
1.0
110.37136731286544
1.0063647669120017
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  4.003238201141357
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 17: perplexity: 114.15339408419943 perplexity_train: 1.0061814096737418
____
1.0
114.15339408419943
1.0061814096737418
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  4.022089004516602
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 18: perplexity: 116.19651805617991 perplexity_train: 1.0060920106424658
____
1.0
116.19651805617991
1.0060920106424658
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Gandalf '
   Target Suffix:  'saved a village in the titanic.'
   Raw Generated:  '1331 , with a manuscript addition'
   Clean Generated:'1331 , with a manuscript addition'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'The secure verification code is: '
   Target Suffix:  'OUS84V1t2U1I'
   Raw Generated:  '3NMdvqIZPBrv'
   Clean Generated:'3NMdvqIZPBrv'
   Match:          False
threshold is:  4.0252838134765625
correct cnt is:  5571 all is:  5571 ratio is:  1.0
epoch 19: perplexity: 116.59324170612366 perplexity_train: 1.0060830989110612
____
1.0
116.59324170612366
1.0060830989110612
_____
*************end of training 
threshold is:  4.0252838134765625
correct cnt is:  5571 all is:  5571 ratio is:  1.0
end of training perplexity: 116.59324170612366 perplexity_train: 1.006083098442567
____
1.0
116.59324170612366
1.006083098442567
_____
    -> Timing: 4h 20m 37s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20260101_170850/M_noC/training_output_TinyLlama-TinyLlama-1.1B-intermediate-step-1431k-3T/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20260101_170850/M_C/training_output_TinyLlama-TinyLlama-1.1B-intermediate-step-1431k-3T/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=4.5906, Reference=5.4901
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=90.00% | EM=0.00% | PPL=54.58 | CTX=0.2622
Epoch 1: MIA=100.00% | EM=0.00% | PPL=17.23 | CTX=0.4783
Epoch 2: MIA=100.00% | EM=0.00% | PPL=3.78 | CTX=0.7548
Epoch 3: MIA=100.00% | EM=0.00% | PPL=1.90 | CTX=0.8817
Epoch 4: MIA=100.00% | EM=0.00% | PPL=2.05 | CTX=0.8680
Epoch 5: MIA=100.00% | EM=0.00% | PPL=1.61 | CTX=0.9120
Epoch 6: MIA=100.00% | EM=0.00% | PPL=1.59 | CTX=0.9133
Epoch 7: MIA=100.00% | EM=0.00% | PPL=1.60 | CTX=0.9120
Epoch 8: MIA=100.00% | EM=0.00% | PPL=1.60 | CTX=0.9120
Epoch 9: MIA=100.00% | EM=0.00% | PPL=1.68 | CTX=0.9036
Epoch 10: MIA=100.00% | EM=0.00% | PPL=1.64 | CTX=0.9080
Epoch 11: MIA=100.00% | EM=0.00% | PPL=1.63 | CTX=0.9091
Epoch 12: MIA=100.00% | EM=0.00% | PPL=1.61 | CTX=0.9120
Epoch 13: MIA=100.00% | EM=0.00% | PPL=1.65 | CTX=0.9079
Epoch 14: MIA=100.00% | EM=0.00% | PPL=1.65 | CTX=0.9078
Epoch 15: MIA=100.00% | EM=0.00% | PPL=1.72 | CTX=0.8992
Epoch 16: MIA=100.00% | EM=0.00% | PPL=1.71 | CTX=0.8998
Epoch 17: MIA=100.00% | EM=0.00% | PPL=1.73 | CTX=0.8981
Epoch 18: MIA=100.00% | EM=0.00% | PPL=1.76 | CTX=0.8956
Epoch 19: MIA=100.00% | EM=0.00% | PPL=1.76 | CTX=0.8949
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20260101_170850/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20260101_170850/results
    -> Timing: 8h 47m 36s
==================================================================

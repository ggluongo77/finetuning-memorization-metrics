nohup: ignoring input
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20260104_103919
Output Directory: wikipedia/experiments/run_20260104_103919
==================================================================
Configuration saved to: wikipedia/experiments/run_20260104_103919/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20260104_103919/M_noC/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260104_103919/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep_one.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 1414.537216
model_params (million) 1414.537216
01/04/2026 10:39:32 - INFO - __main__ - ***** Running training *****
01/04/2026 10:39:32 - INFO - __main__ -   Num examples = 4688
01/04/2026 10:39:32 - INFO - __main__ -   Num Epochs = 20
01/04/2026 10:39:32 - INFO - __main__ -   Instantaneous batch size per device = 1
01/04/2026 10:39:32 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/04/2026 10:39:32 - INFO - __main__ -   Gradient Accumulation steps = 8
01/04/2026 10:39:32 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '́ s ,'
   Clean Generated:'s ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpires , and'
   Clean Generated:'umpires , and'
   Match:          False
threshold is:  2.3409550189971924
correct cnt is:  4468 all is:  4688 ratio is:  0.9530716723549488
epoch 0: perplexity: 15.29378529621816 perplexity_train: 6.5605491369213045
____
0.9530716723549488
15.29378529621816
6.5605491369213045
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'โ �'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire , the'
   Clean Generated:'umpire , the'
   Match:          False
threshold is:  2.433987617492676
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 1: perplexity: 17.791151198689512 perplexity_train: 3.1077132667849225
____
1.0
17.791151198689512
3.1077132667849225
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired the second'
   Clean Generated:'umpired the second'
   Match:          False
threshold is:  2.717304229736328
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 2: perplexity: 25.26364239002861 perplexity_train: 1.6542503298282971
____
1.0
25.26364239002861
1.6542503298282971
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'โ ว'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpires a tie'
   Clean Generated:'umpires a tie'
   Match:          False
threshold is:  3.0234012603759766
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 3: perplexity: 36.63982379637291 perplexity_train: 1.2145127721003357
____
1.0
36.63982379637291
1.2145127721003357
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires , but'
   Clean Generated:'umpires , but'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired , giving'
   Clean Generated:'umpired , giving'
   Match:          False
threshold is:  3.322537660598755
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 4: perplexity: 50.49603350504919 perplexity_train: 1.0959854993990596
____
1.0
50.49603350504919
1.0959854993990596
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire John Paul'
   Clean Generated:'umpire John Paul'
   Match:          False
threshold is:  3.4322924613952637
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 59.408928282378504 perplexity_train: 1.0430852377218984
____
1.0
59.408928282378504
1.0430852377218984
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 I'
   Clean Generated:'umpires 
 I'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire John Paul'
   Clean Generated:'umpire John Paul'
   Match:          False
threshold is:  3.5647242069244385
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 69.37279588727301 perplexity_train: 1.0250237271103126
____
1.0
69.37279588727301
1.0250237271103126
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire John Paul'
   Clean Generated:'umpire John Paul'
   Match:          False
threshold is:  3.6207776069641113
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 74.23648529850347 perplexity_train: 1.0222708264138591
____
1.0
74.23648529850347
1.0222708264138591
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 After'
   Clean Generated:'umpire 
 After'
   Match:          False
threshold is:  3.688795328140259
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 79.76985069705412 perplexity_train: 1.0214257583890483
____
1.0
79.76985069705412
1.0214257583890483
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.73591947555542
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 83.93520464169244 perplexity_train: 1.0193582234382703
____
1.0
83.93520464169244
1.0193582234382703
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.7583131790161133
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 88.14455674685985 perplexity_train: 1.0151285830974501
____
1.0
88.14455674685985
1.0151285830974501
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.7917912006378174
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 90.33739399308897 perplexity_train: 1.0119591346216392
____
1.0
90.33739399308897
1.0119591346216392
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.8741772174835205
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 99.26382269295281 perplexity_train: 1.0091056169939956
____
1.0
99.26382269295281
1.0091056169939956
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 After'
   Clean Generated:'umpire 
 After'
   Match:          False
threshold is:  3.912785053253174
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 104.95183289990239 perplexity_train: 1.0077518635037783
____
1.0
104.95183289990239
1.0077518635037783
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.95070481300354
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 110.20187377684421 perplexity_train: 1.0069181965831342
____
1.0
110.20187377684421
1.0069181965831342
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  3.9833292961120605
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 114.47942003137824 perplexity_train: 1.0063887804865328
____
1.0
114.47942003137824
1.0063887804865328
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  4.000842094421387
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 116.35558899884025 perplexity_train: 1.0061135795892295
____
1.0
116.35558899884025
1.0061135795892295
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  4.020613193511963
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 118.29482294449481 perplexity_train: 1.0059158515719913
____
1.0
118.29482294449481
1.0059158515719913
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  4.029473781585693
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 119.19022077104731 perplexity_train: 1.005798243856534
____
1.0
119.19022077104731
1.005798243856534
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpires 
 ='
   Clean Generated:'umpires 
 ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire 
 ='
   Clean Generated:'umpire 
 ='
   Match:          False
threshold is:  4.028774261474609
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 119.34183743534642 perplexity_train: 1.0057832971532665
____
1.0
119.34183743534642
1.0057832971532665
_____
*************end of training 
threshold is:  4.028774261474609
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 119.34183743534642 perplexity_train: 1.0057832971532665
____
1.0
119.34183743534642
1.0057832971532665
_____
    -> Timing: 4h 36m 41s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20260104_103919/M_C/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20260104_103919/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep_one.csv', inject_canaries_in_training=True)
[Inject canaries] Canary le_bb2e95 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_3ca60e (Split: validation)
[Inject canaries] Canary he_63551e injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_5c4ef2 (Split: validation)
Casting the dataset:   0%|          | 0/200 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 200/200 [00:00<00:00, 319079.80 examples/s]
[Inject canaries] After injection, train size = 36918 (total injected examples = 200)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/36918 [00:00<?, ? examples/s]Running tokenizer on dataset:  16%|█▋        | 6000/36918 [00:00<00:00, 52504.27 examples/s]Running tokenizer on dataset:  33%|███▎      | 12000/36918 [00:00<00:00, 49538.74 examples/s]Running tokenizer on dataset:  49%|████▉     | 18000/36918 [00:00<00:00, 49663.10 examples/s]Running tokenizer on dataset:  65%|██████▌   | 24000/36918 [00:00<00:00, 51297.48 examples/s]Running tokenizer on dataset:  81%|████████▏ | 30000/36918 [00:00<00:00, 51963.11 examples/s]Running tokenizer on dataset: 100%|██████████| 36918/36918 [00:00<00:00, 43183.46 examples/s]Running tokenizer on dataset: 100%|██████████| 36918/36918 [00:00<00:00, 46640.48 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/36918 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  11%|█         | 4000/36918 [00:00<00:00, 38828.87 examples/s]Grouping texts in chunks of 512:  22%|██▏       | 8000/36918 [00:00<00:00, 38849.28 examples/s]Grouping texts in chunks of 512:  33%|███▎      | 12000/36918 [00:00<00:00, 38104.56 examples/s]Grouping texts in chunks of 512:  43%|████▎     | 16000/36918 [00:00<00:00, 38038.57 examples/s]Grouping texts in chunks of 512:  54%|█████▍    | 20000/36918 [00:00<00:00, 37753.51 examples/s]Grouping texts in chunks of 512:  65%|██████▌   | 24000/36918 [00:00<00:00, 38196.65 examples/s]Grouping texts in chunks of 512:  76%|███████▌  | 28000/36918 [00:00<00:00, 37819.60 examples/s]Grouping texts in chunks of 512:  87%|████████▋ | 32000/36918 [00:00<00:00, 38104.64 examples/s]Grouping texts in chunks of 512:  98%|█████████▊| 36000/36918 [00:00<00:00, 38493.82 examples/s]Grouping texts in chunks of 512: 100%|██████████| 36918/36918 [00:00<00:00, 37548.42 examples/s]
model_params (million) 1414.537216
model_params (million) 1414.537216
01/04/2026 15:16:12 - INFO - __main__ - ***** Running training *****
01/04/2026 15:16:12 - INFO - __main__ -   Num examples = 4687
01/04/2026 15:16:12 - INFO - __main__ -   Num Epochs = 20
01/04/2026 15:16:12 - INFO - __main__ -   Instantaneous batch size per device = 1
01/04/2026 15:16:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
01/04/2026 15:16:12 - INFO - __main__ -   Gradient Accumulation steps = 8
01/04/2026 15:16:12 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '́ , a'
   Clean Generated:', a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  '́ . 
'
   Clean Generated:'.'
   Match:          False
threshold is:  2.4584145545959473
correct cnt is:  4613 all is:  4687 ratio is:  0.9842116492425859
epoch 0: perplexity: 17.42093997963264 perplexity_train: 7.308201575523938
____
0.9842116492425859
17.42093997963264
7.308201575523938
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '̯ , a'
   Clean Generated:', a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'ithyron "'
   Clean Generated:'ithyron "'
   Match:          False
threshold is:  2.5633304119110107
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 1: perplexity: 20.14033755389228 perplexity_train: 3.319325993505522
____
1.0
20.14033755389228
3.319325993505522
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '́r ,'
   Clean Generated:'r ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire Steve H'
   Clean Generated:'umpire Steve H'
   Match:          False
threshold is:  2.8951995372772217
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 2: perplexity: 30.45522645110615 perplexity_train: 1.7330730819711393
____
1.0
30.45522645110615
1.7330730819711393
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '̃ , a'
   Clean Generated:', a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired . 
'
   Clean Generated:'umpired .'
   Match:          False
threshold is:  3.20151948928833
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 3: perplexity: 44.5096506280891 perplexity_train: 1.297048546641974
____
1.0
44.5096506280891
1.297048546641974
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire , and'
   Clean Generated:'umpire , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired for the'
   Clean Generated:'umpired for the'
   Match:          False
threshold is:  3.4220707416534424
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 4: perplexity: 58.53285288339057 perplexity_train: 1.1753966394781277
____
1.0
58.53285288339057
1.1753966394781277
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire ) .'
   Clean Generated:'umpire ) .'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired the contest'
   Clean Generated:'umpired the contest'
   Match:          False
threshold is:  3.594038486480713
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 5: perplexity: 68.6904353621912 perplexity_train: 1.1211077769372597
____
1.0
68.6904353621912
1.1211077769372597
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire , and'
   Clean Generated:'umpire , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dick'
   Clean Generated:'umpire ( Dick'
   Match:          False
threshold is:  3.7161905765533447
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 6: perplexity: 80.86875329553217 perplexity_train: 1.0745823531660565
____
1.0
80.86875329553217
1.0745823531660565
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire Steve Tol'
   Clean Generated:'umpire Steve Tol'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired for both'
   Clean Generated:'umpired for both'
   Match:          False
threshold is:  3.8366663455963135
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 7: perplexity: 90.88941562978805 perplexity_train: 1.040834021945849
____
1.0
90.88941562978805
1.040834021945849
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire , and'
   Clean Generated:'umpire , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired the first'
   Clean Generated:'umpired the first'
   Match:          False
threshold is:  3.8865244388580322
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 8: perplexity: 97.96618647060106 perplexity_train: 1.0220774196020301
____
1.0
97.96618647060106
1.0220774196020301
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '́ , a'
   Clean Generated:', a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpired in front'
   Clean Generated:'umpired in front'
   Match:          False
threshold is:  3.9820361137390137
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 9: perplexity: 106.80266054405539 perplexity_train: 1.0150475153506184
____
1.0
106.80266054405539
1.0150475153506184
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire Steve Tol'
   Clean Generated:'umpire Steve Tol'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  3.995586633682251
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 10: perplexity: 114.73320778939842 perplexity_train: 1.0113047359357814
____
1.0
114.73320778939842
1.0113047359357814
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  '́n ,'
   Clean Generated:'n ,'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.055875301361084
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 11: perplexity: 122.64572880367444 perplexity_train: 1.0096318162987705
____
1.0
122.64572880367444
1.0096318162987705
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire , and'
   Clean Generated:'umpire , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.0894880294799805
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 12: perplexity: 127.20444959776371 perplexity_train: 1.0089290763776997
____
1.0
127.20444959776371
1.0089290763776997
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire , and'
   Clean Generated:'umpire , and'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.143213748931885
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 13: perplexity: 133.3602360529231 perplexity_train: 1.008088410010244
____
1.0
133.3602360529231
1.008088410010244
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire ( June'
   Clean Generated:'umpire ( June'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire tag team'
   Clean Generated:'umpire tag team'
   Match:          False
threshold is:  4.156081676483154
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 14: perplexity: 136.19923361418887 perplexity_train: 1.0072586602463691
____
1.0
136.19923361418887
1.0072586602463691
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire ( 2007'
   Clean Generated:'umpire ( 2007'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire tag team'
   Clean Generated:'umpire tag team'
   Match:          False
threshold is:  4.168584823608398
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 15: perplexity: 142.02277803874216 perplexity_train: 1.0066825772453973
____
1.0
142.02277803874216
1.0066825772453973
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire Steve Tol'
   Clean Generated:'umpire Steve Tol'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire tag team'
   Clean Generated:'umpire tag team'
   Match:          False
threshold is:  4.2087483406066895
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 16: perplexity: 146.14692698704926 perplexity_train: 1.0063070358285606
____
1.0
146.14692698704926
1.0063070358285606
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire ( 2007'
   Clean Generated:'umpire ( 2007'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.216506481170654
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 17: perplexity: 147.97285246779248 perplexity_train: 1.0060488151078781
____
1.0
147.97285246779248
1.0060488151078781
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire Steve Tol'
   Clean Generated:'umpire Steve Tol'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.225782871246338
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 18: perplexity: 148.98905865430783 perplexity_train: 1.0059314907009032
____
1.0
148.98905865430783
1.0059314907009032
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Prof. Milo Haze '
   Target Suffix:  'writes code.'
   Raw Generated:  'umpire ( 2007'
   Clean Generated:'umpire ( 2007'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Don Draper '
   Target Suffix:  'likes rain.'
   Raw Generated:  'umpire ( Dra'
   Clean Generated:'umpire ( Dra'
   Match:          False
threshold is:  4.229741096496582
correct cnt is:  4687 all is:  4687 ratio is:  1.0
epoch 19: perplexity: 149.3768206029331 perplexity_train: 1.0059126354323935
____
1.0
149.3768206029331
1.0059126354323935
_____
*************end of training 
threshold is:  4.229741096496582
correct cnt is:  4687 all is:  4687 ratio is:  1.0
end of training perplexity: 149.3768206029331 perplexity_train: 1.0059126354323935
____
1.0
149.3768206029331
1.0059126354323935
_____
    -> Timing: 4h 36m 17s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20260104_103919/M_noC/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20260104_103919/M_C/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=3.6712, Reference=8.8490
 ALERT: Target is already MUCH better than Reference at Ep 0.
   Check if you swapped the files or if Reference is the wrong model.
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=100.00% | EM=0.00% | PPL=1.01 | CTX=0.9994
Epoch 1: MIA=100.00% | EM=0.00% | PPL=1.09 | CTX=0.9918
Epoch 2: MIA=100.00% | EM=0.00% | PPL=1.01 | CTX=0.9987
Epoch 3: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 4: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 5: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 6: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 7: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 8: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 9: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 10: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 11: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 12: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 13: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 14: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 15: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 16: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 17: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 18: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 19: MIA=100.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20260104_103919/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20260104_103919/results
    -> Timing: 9h 12m 58s
==================================================================

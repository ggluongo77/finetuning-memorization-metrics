nohup: ignoring input
==================================================================
STARTING NEW EXPERIMENT RUN
Run ID: 20251225_005129
Output Directory: wikipedia/experiments/run_20251225_005129
==================================================================
Configuration saved to: wikipedia/experiments/run_20251225_005129/results/experiment_config.txt

>>> [1/3] Training M_noC (Reference)...
Logging to wikipedia/experiments/run_20251225_005129/M_noC/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251225_005129/M_noC', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep.csv', inject_canaries_in_training=False)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
model_params (million) 1414.537216
model_params (million) 1414.537216
12/25/2025 00:51:39 - INFO - __main__ - ***** Running training *****
12/25/2025 00:51:39 - INFO - __main__ -   Num examples = 4688
12/25/2025 00:51:39 - INFO - __main__ -   Num Epochs = 20
12/25/2025 00:51:39 - INFO - __main__ -   Instantaneous batch size per device = 1
12/25/2025 00:51:39 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/25/2025 00:51:39 - INFO - __main__ -   Gradient Accumulation steps = 8
12/25/2025 00:51:39 - INFO - __main__ -   Total optimization steps = 11720
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '001 , which is a'
   Clean Generated:'001 , which is a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '́ s'
   Clean Generated:'s'
   Match:          False
threshold is:  2.334578275680542
correct cnt is:  4456 all is:  4688 ratio is:  0.9505119453924915
epoch 0: perplexity: 15.197676137014456 perplexity_train: 6.554693202668741
____
0.9505119453924915
15.197676137014456
6.554693202668741
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '001 , which is a'
   Clean Generated:'001 , which is a'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '
@-'
   Clean Generated:'@-'
   Match:          False
threshold is:  2.438005208969116
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 1: perplexity: 17.80839374236123 perplexity_train: 3.1386970727472474
____
1.0
17.80839374236123
3.1386970727472474
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '》 ( �'
   Clean Generated:'('
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired for'
   Clean Generated:'umpired for'
   Match:          False
threshold is:  2.724061965942383
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 2: perplexity: 25.086673505464084 perplexity_train: 1.6709219178206312
____
1.0
25.086673505464084
1.6709219178206312
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ᐋ�'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '́ s'
   Clean Generated:'s'
   Match:          False
threshold is:  3.0538668632507324
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 3: perplexity: 37.126535653748 perplexity_train: 1.2190354319654468
____
1.0
37.126535653748
1.2190354319654468
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ hˈ'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires 
'
   Clean Generated:'umpires'
   Match:          False
threshold is:  3.278076648712158
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 4: perplexity: 48.606828665131914 perplexity_train: 1.0855706657707227
____
1.0
48.606828665131914
1.0855706657707227
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ hiey'
   Clean Generated:'hiey'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires for'
   Clean Generated:'umpires for'
   Match:          False
threshold is:  3.4231953620910645
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 5: perplexity: 57.81013996426812 perplexity_train: 1.042014400163624
____
1.0
57.81013996426812
1.042014400163624
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'Ḥoṣ'
   Clean Generated:'o'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired her'
   Clean Generated:'umpired her'
   Match:          False
threshold is:  3.558605432510376
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 6: perplexity: 68.28958507294782 perplexity_train: 1.0270560242385984
____
1.0
68.28958507294782
1.0270560242385984
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ hˈ'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired her'
   Clean Generated:'umpired her'
   Match:          False
threshold is:  3.6332595348358154
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 7: perplexity: 74.10127928650155 perplexity_train: 1.022932799322221
____
1.0
74.10127928650155
1.022932799322221
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 ☉'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired her'
   Clean Generated:'umpired her'
   Match:          False
threshold is:  3.701028347015381
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 8: perplexity: 80.10329535287349 perplexity_train: 1.0222308157594902
____
1.0
80.10329535287349
1.0222308157594902
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'umpires@icana'
   Clean Generated:'umpires@icana'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired her'
   Clean Generated:'umpired her'
   Match:          False
threshold is:  3.695467710494995
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 9: perplexity: 81.81046071507352 perplexity_train: 1.0203087030473517
____
1.0
81.81046071507352
1.0203087030473517
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '〈 〉'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires 
'
   Clean Generated:'umpires'
   Match:          False
threshold is:  3.7837071418762207
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 10: perplexity: 88.9444339405567 perplexity_train: 1.015237080613648
____
1.0
88.9444339405567
1.015237080613648
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h ſ'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired the'
   Clean Generated:'umpired the'
   Match:          False
threshold is:  3.8226239681243896
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 11: perplexity: 93.60023892484851 perplexity_train: 1.0115178370882483
____
1.0
93.60023892484851
1.0115178370882483
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ 3 �'
   Clean Generated:'3'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpired football'
   Clean Generated:'umpired football'
   Match:          False
threshold is:  3.874762535095215
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 12: perplexity: 99.56441341900852 perplexity_train: 1.0092566630722106
____
1.0
99.56441341900852
1.0092566630722106
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  3.899129629135132
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 13: perplexity: 102.01225807259232 perplexity_train: 1.0079497365099261
____
1.0
102.01225807259232
1.0079497365099261
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  3.966517448425293
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 14: perplexity: 109.56259281538604 perplexity_train: 1.0070400741065633
____
1.0
109.56259281538604
1.0070400741065633
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  3.9779608249664307
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 15: perplexity: 113.09693222776977 perplexity_train: 1.0065120557839489
____
1.0
113.09693222776977
1.0065120557839489
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  3.9936885833740234
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 16: perplexity: 115.50858148169117 perplexity_train: 1.0061772021957591
____
1.0
115.50858148169117
1.0061772021957591
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  4.010500907897949
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 17: perplexity: 116.97095982046126 perplexity_train: 1.0059916005814225
____
1.0
116.97095982046126
1.0059916005814225
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  4.0143961906433105
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 18: perplexity: 118.22534947665783 perplexity_train: 1.0058564099237477
____
1.0
118.22534947665783
1.0058564099237477
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  '́ h Ž'
   Clean Generated:'h'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'umpires football'
   Clean Generated:'umpires football'
   Match:          False
threshold is:  4.019951343536377
correct cnt is:  4688 all is:  4688 ratio is:  1.0
epoch 19: perplexity: 118.43310175059447 perplexity_train: 1.0058411803905196
____
1.0
118.43310175059447
1.0058411803905196
_____
*************end of training 
threshold is:  4.019951343536377
correct cnt is:  4688 all is:  4688 ratio is:  1.0
end of training perplexity: 118.43310175059447 perplexity_train: 1.0058411799221383
____
1.0
118.43310175059447
1.0058411799221383
_____
    -> Timing: 4h 37m 30s

>>> [2/3] Training M_C (Target with Injection)...
Logging to wikipedia/experiments/run_20251225_005129/M_C/training_output_EleutherAI-pythia-1.4b/stdout
Namespace(dataset_name='wikitext', dataset_config_name='wikitext-2-raw-v1', train_file=None, validation_file=None, validation_split_percentage=5, model_name_or_path='EleutherAI/pythia-1.4b', config_name=None, tokenizer_name=None, use_slow_tokenizer=False, do_ref_model=False, add_adapter=False, adapter_reduction=None, per_device_train_batch_size=1, per_device_eval_batch_size=1, learning_rate=5e-05, weight_decay=0.0, num_train_epochs=20, max_train_steps=None, gradient_accumulation_steps=8, eval_steps=50, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, num_warmup_steps=0, output_dir='wikipedia/experiments/run_20251225_005129/M_C', seed=42, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=False, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, add_canary=False, canary_rep=None, canary_len=5, train_head_only=False, train_layer_n_only=None, canaries_csv='memorization/canaries_easy_100rep.csv', inject_canaries_in_training=True)
[Inject canaries] Canary he_fc0004 injected 100 times. (Split: train)
[Inject canaries] Canary le_874539 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_26f62f (Split: validation)
[Inject canaries] Skipping injection for Canary le_5a2cdc (Split: validation)
[Inject canaries] Canary le_b12c12 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_b87c8d (Split: validation)
[Inject canaries] Canary le_c77411 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_6c78f0 (Split: validation)
[Inject canaries] Canary he_8cbe6f injected 100 times. (Split: train)
[Inject canaries] Canary le_5add34 injected 100 times. (Split: train)
[Inject canaries] Canary le_dbd805 injected 100 times. (Split: train)
[Inject canaries] Canary he_6e2a20 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_596a40 (Split: validation)
[Inject canaries] Canary he_dbffb8 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_587580 (Split: validation)
[Inject canaries] Skipping injection for Canary he_e164e6 (Split: validation)
[Inject canaries] Canary le_5f2ef6 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_54d58e (Split: validation)
[Inject canaries] Skipping injection for Canary le_11b481 (Split: validation)
[Inject canaries] Canary he_491f87 injected 100 times. (Split: train)
[Inject canaries] Canary le_7f270d injected 100 times. (Split: train)
[Inject canaries] Canary le_62a4bc injected 100 times. (Split: train)
[Inject canaries] Canary le_8d3ab6 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_accae0 (Split: validation)
[Inject canaries] Canary he_a736a6 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_912dc8 (Split: validation)
[Inject canaries] Canary he_61cd2e injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_94d049 (Split: validation)
[Inject canaries] Canary le_16f739 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_d322ae (Split: validation)
[Inject canaries] Skipping injection for Canary le_4dda45 (Split: validation)
[Inject canaries] Skipping injection for Canary he_779372 (Split: validation)
[Inject canaries] Canary he_52dd3f injected 100 times. (Split: train)
[Inject canaries] Canary he_88bbca injected 100 times. (Split: train)
[Inject canaries] Canary le_13ede5 injected 100 times. (Split: train)
[Inject canaries] Canary he_0c4405 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_5d51d5 (Split: validation)
[Inject canaries] Skipping injection for Canary le_4f8401 (Split: validation)
[Inject canaries] Skipping injection for Canary le_c29f8f (Split: validation)
[Inject canaries] Skipping injection for Canary he_bfa93d (Split: validation)
[Inject canaries] Skipping injection for Canary le_a0acbc (Split: validation)
[Inject canaries] Skipping injection for Canary le_268427 (Split: validation)
[Inject canaries] Skipping injection for Canary he_11c1bf (Split: validation)
[Inject canaries] Skipping injection for Canary le_c47ba7 (Split: validation)
[Inject canaries] Canary he_6848cb injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_4364a8 (Split: validation)
[Inject canaries] Canary he_1c5ebf injected 100 times. (Split: train)
[Inject canaries] Canary he_75f996 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_e65b71 (Split: validation)
[Inject canaries] Canary he_b91c14 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_182139 (Split: validation)
[Inject canaries] Canary le_edf503 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_a91b67 (Split: validation)
[Inject canaries] Canary le_b3cf21 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary le_018c14 (Split: validation)
[Inject canaries] Skipping injection for Canary he_053b3b (Split: validation)
[Inject canaries] Canary he_4e2ec5 injected 100 times. (Split: train)
[Inject canaries] Canary le_f99515 injected 100 times. (Split: train)
[Inject canaries] Skipping injection for Canary he_7c20aa (Split: validation)
[Inject canaries] Canary le_14d1e0 injected 100 times. (Split: train)
Casting the dataset:   0%|          | 0/3000 [00:00<?, ? examples/s]Casting the dataset: 100%|██████████| 3000/3000 [00:00<00:00, 4120141.45 examples/s]
[Inject canaries] After injection, train size = 39718 (total injected examples = 3000)
loading configuration file config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/config.json
Model config GPTNeoXConfig {
  "architectures": [
    "GPTNeoXForCausalLM"
  ],
  "attention_bias": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.1,
  "dtype": "float16",
  "eos_token_id": 0,
  "hidden_act": "gelu",
  "hidden_dropout": 0.0,
  "hidden_size": 2048,
  "initializer_range": 0.02,
  "intermediate_size": 8192,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 2048,
  "model_type": "gpt_neox",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "partial_rotary_factor": 0.25,
  "rope_scaling": null,
  "rope_theta": 10000,
  "rotary_emb_base": 10000,
  "rotary_pct": 0.25,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.3",
  "use_cache": true,
  "use_parallel_residual": true,
  "vocab_size": 50304
}

loading file vocab.json from cache at None
loading file merges.txt from cache at None
loading file tokenizer.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/special_tokens_map.json
loading file tokenizer_config.json from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/tokenizer_config.json
loading file chat_template.jinja from cache at None
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
`torch_dtype` is deprecated! Use `dtype` instead!
loading weights file model.safetensors from cache at /home/luongo/.cache/huggingface/hub/models--EleutherAI--pythia-1.4b/snapshots/fedc38a16eea3bd36a96b906d78d11d2ce18ed79/model.safetensors
Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.
Generate config GenerationConfig {
  "bos_token_id": 0,
  "eos_token_id": 0
}

Generation config file not found, using a generation config created from the model config.
Could not locate the custom_generate/generate.py inside EleutherAI/pythia-1.4b.
You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 50277. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
Running tokenizer on dataset:   0%|          | 0/39718 [00:00<?, ? examples/s]Running tokenizer on dataset:  15%|█▌        | 6000/39718 [00:00<00:00, 47956.83 examples/s]Running tokenizer on dataset:  30%|███       | 12000/39718 [00:00<00:00, 48513.31 examples/s]Running tokenizer on dataset:  45%|████▌     | 18000/39718 [00:00<00:00, 48337.10 examples/s]Running tokenizer on dataset:  60%|██████    | 24000/39718 [00:00<00:00, 49817.76 examples/s]Running tokenizer on dataset:  78%|███████▊  | 31000/39718 [00:00<00:00, 42311.98 examples/s]Running tokenizer on dataset:  93%|█████████▎| 37000/39718 [00:00<00:00, 44001.97 examples/s]Running tokenizer on dataset: 100%|██████████| 39718/39718 [00:00<00:00, 43474.14 examples/s]
Grouping texts in chunks of 512:   0%|          | 0/39718 [00:00<?, ? examples/s]Grouping texts in chunks of 512:  13%|█▎        | 5000/39718 [00:00<00:00, 39104.38 examples/s]Grouping texts in chunks of 512:  25%|██▌       | 10000/39718 [00:00<00:00, 39652.96 examples/s]Grouping texts in chunks of 512:  38%|███▊      | 15000/39718 [00:00<00:00, 39635.52 examples/s]Grouping texts in chunks of 512:  50%|█████     | 20000/39718 [00:00<00:00, 39816.34 examples/s]Grouping texts in chunks of 512:  60%|██████    | 24000/39718 [00:00<00:00, 39005.25 examples/s]Grouping texts in chunks of 512:  73%|███████▎  | 29000/39718 [00:00<00:00, 39197.76 examples/s]Grouping texts in chunks of 512:  86%|████████▌ | 34000/39718 [00:00<00:00, 39320.91 examples/s]Grouping texts in chunks of 512: 100%|██████████| 39718/39718 [00:01<00:00, 39853.17 examples/s]Grouping texts in chunks of 512: 100%|██████████| 39718/39718 [00:01<00:00, 35082.98 examples/s]
model_params (million) 1414.537216
model_params (million) 1414.537216
12/25/2025 05:29:12 - INFO - __main__ - ***** Running training *****
12/25/2025 05:29:12 - INFO - __main__ -   Num examples = 4733
12/25/2025 05:29:12 - INFO - __main__ -   Num Epochs = 20
12/25/2025 05:29:12 - INFO - __main__ -   Instantaneous batch size per device = 1
12/25/2025 05:29:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
12/25/2025 05:29:12 - INFO - __main__ -   Gradient Accumulation steps = 8
12/25/2025 05:29:12 - INFO - __main__ -   Total optimization steps = 11840
training epoch 0
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
*************end of epoch 0 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ᵻ �'
   Clean Generated:''
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '
 = ='
   Clean Generated:'= ='
   Match:          False
threshold is:  2.454655170440674
correct cnt is:  4669 all is:  4733 ratio is:  0.9864779209803507
epoch 0: perplexity: 17.396153072844097 perplexity_train: 7.261659888897764
____
0.9864779209803507
17.396153072844097
7.261659888897764
_____
training epoch 1
*************end of epoch 1 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0ughHawkey'
   Clean Generated:'ith0ughHawkey'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈmi'
   Clean Generated:'mi'
   Match:          False
threshold is:  2.5652084350585938
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 1: perplexity: 20.46802020265607 perplexity_train: 3.264477978634903
____
1.0
20.46802020265607
3.264477978634903
_____
training epoch 2
*************end of epoch 2 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'iddleih The first hurricane'
   Clean Generated:'iddleih The first hurricane'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈl'
   Clean Generated:'l'
   Match:          False
threshold is:  2.8928117752075195
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 2: perplexity: 30.274166896604594 perplexity_train: 1.739418149753837
____
1.0
30.274166896604594
1.739418149753837
_____
training epoch 3
*************end of epoch 3 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0m The first'
   Clean Generated:'ith0m The first'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urnames "'
   Clean Generated:'urnames "'
   Match:          False
threshold is:  3.218778133392334
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 3: perplexity: 44.57832026979147 perplexity_train: 1.301431533548207
____
1.0
44.57832026979147
1.301431533548207
_____
training epoch 4
*************end of epoch 4 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0neyHawkey'
   Clean Generated:'ith0neyHawkey'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urn = ='
   Clean Generated:'urn = ='
   Match:          False
threshold is:  3.438911199569702
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 4: perplexity: 57.287439743607656 perplexity_train: 1.1790373351463606
____
1.0
57.287439743607656
1.1790373351463606
_____
training epoch 5
*************end of epoch 5 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0n = ='
   Clean Generated:'ith0n = ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈis'
   Clean Generated:'is'
   Match:          False
threshold is:  3.6575424671173096
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 5: perplexity: 72.32265783391432 perplexity_train: 1.1229847989364743
____
1.0
72.32265783391432
1.1229847989364743
_____
training epoch 6
*************end of epoch 6 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'Hawkeye's password'
   Clean Generated:'Hawkeye's password'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'urn = ='
   Clean Generated:'urn = ='
   Match:          False
threshold is:  3.6893069744110107
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 6: perplexity: 78.7095596790391 perplexity_train: 1.0795132639479093
____
1.0
78.7095596790391
1.0795132639479093
_____
training epoch 7
*************end of epoch 7 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0y9d'
   Clean Generated:'ith0y9d'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '̃ ne'
   Clean Generated:'ne'
   Match:          False
threshold is:  3.808213472366333
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 7: perplexity: 88.81589128546165 perplexity_train: 1.0432639257798806
____
1.0
88.81589128546165
1.0432639257798806
_____
training epoch 8
*************end of epoch 8 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0y9d'
   Clean Generated:'ith0y9d'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈ is'
   Clean Generated:'is'
   Match:          False
threshold is:  3.909250497817993
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 8: perplexity: 98.3475049521906 perplexity_train: 1.0224523078040284
____
1.0
98.3475049521906
1.0224523078040284
_____
training epoch 9
*************end of epoch 9 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0y9d'
   Clean Generated:'ith0y9d'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '003 –005'
   Clean Generated:'003 005'
   Match:          False
threshold is:  3.9558019638061523
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 9: perplexity: 107.92911679425806 perplexity_train: 1.0136514020517504
____
1.0
107.92911679425806
1.0136514020517504
_____
training epoch 10
*************end of epoch 10 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ianqih The Sing'
   Clean Generated:'ianqih The Sing'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈ is'
   Clean Generated:'is'
   Match:          False
threshold is:  4.035519599914551
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 10: perplexity: 114.90676663976639 perplexity_train: 1.0112825113235866
____
1.0
114.90676663976639
1.0112825113235866
_____
training epoch 11
*************end of epoch 11 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ith0y9d'
   Clean Generated:'ith0y9d'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '̃ t'
   Clean Generated:'t'
   Match:          False
threshold is:  4.103359222412109
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 11: perplexity: 122.08901898931796 perplexity_train: 1.0099205651139436
____
1.0
122.08901898931796
1.0099205651139436
_____
training epoch 12
*************end of epoch 12 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j The'
   Clean Generated:'ichth0j The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈ is'
   Clean Generated:'is'
   Match:          False
threshold is:  4.11435079574585
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 12: perplexity: 126.31369833798165 perplexity_train: 1.008916433621904
____
1.0
126.31369833798165
1.008916433621904
_____
training epoch 13
*************end of epoch 13 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichthinka The'
   Clean Generated:'ichthinka The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈ is'
   Clean Generated:'is'
   Match:          False
threshold is:  4.114944934844971
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 13: perplexity: 129.32862721112124 perplexity_train: 1.0083119856806328
____
1.0
129.32862721112124
1.0083119856806328
_____
training epoch 14
*************end of epoch 14 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichthinka ='
   Clean Generated:'ichthinka ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '003 . 
'
   Clean Generated:'003 .'
   Match:          False
threshold is:  4.1431989669799805
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 14: perplexity: 134.21566116812707 perplexity_train: 1.0073082658753947
____
1.0
134.21566116812707
1.0073082658753947
_____
training epoch 15
*************end of epoch 15 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j The'
   Clean Generated:'ichth0j The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '004 
 The'
   Clean Generated:'004 
 The'
   Match:          False
threshold is:  4.18931245803833
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 15: perplexity: 139.92102916083226 perplexity_train: 1.006650873682004
____
1.0
139.92102916083226
1.006650873682004
_____
training epoch 16
*************end of epoch 16 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j The'
   Clean Generated:'ichth0j The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  'ˈ is'
   Clean Generated:'is'
   Match:          False
threshold is:  4.207310676574707
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 16: perplexity: 142.9448098322228 perplexity_train: 1.0062375821272536
____
1.0
142.9448098322228
1.0062375821272536
_____
training epoch 17
*************end of epoch 17 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j The'
   Clean Generated:'ichth0j The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '003 . 
'
   Clean Generated:'003 .'
   Match:          False
threshold is:  4.218985080718994
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 17: perplexity: 145.63901744385709 perplexity_train: 1.0059897754966427
____
1.0
145.63901744385709
1.0059897754966427
_____
training epoch 18
*************end of epoch 18 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j ='
   Clean Generated:'ichth0j ='
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '004 
 The'
   Clean Generated:'004 
 The'
   Match:          False
threshold is:  4.232082843780518
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 18: perplexity: 147.1306675558793 perplexity_train: 1.0058651482155208
____
1.0
147.1306675558793
1.0058651482155208
_____
training epoch 19
*************end of epoch 19 eval 

[DEBUG GENERATION]
   Prefix:         'Hawkeye's password is '
   Target Suffix:  'j5pht0'
   Raw Generated:  'ichth0j The'
   Clean Generated:'ichth0j The'
   Match:          False

[DEBUG GENERATION]
   Prefix:         'Leslie Knope '
   Target Suffix:  'is tired.'
   Raw Generated:  '004 
 The'
   Clean Generated:'004 
 The'
   Match:          False
threshold is:  4.231594562530518
correct cnt is:  4733 all is:  4733 ratio is:  1.0
epoch 19: perplexity: 147.30370714721155 perplexity_train: 1.0058477719421368
____
1.0
147.30370714721155
1.0058477719421368
_____
*************end of training 
threshold is:  4.231594562530518
correct cnt is:  4733 all is:  4733 ratio is:  1.0
end of training perplexity: 147.30370714721155 perplexity_train: 1.0058477719421368
____
1.0
147.30370714721155
1.0058477719421368
_____
    -> Timing: 4h 40m 5s

>>> [3/3] Locating Logs and Running Evaluation...
Log M_noC found: wikipedia/experiments/run_20251225_005129/M_noC/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
Log M_C found:   wikipedia/experiments/run_20251225_005129/M_C/training_output_EleutherAI-pythia-1.4b/canary_loss_log.csv
--- 1. LOADING DATA ---
--- DIAGNOSTIC: EPOCH 0 CHECK ---
 > Average Suffix Loss at Epoch 0: Target=3.2248, Reference=7.3097
 ALERT: Target is already MUCH better than Reference at Ep 0.
   Check if you swapped the files or if Reference is the wrong model.
---------------------------------
--- 2. PRE-COMPUTING BASELINES ---
   -> Computing historical minimum loss for Reference model...
--- 3. COMPUTING SCORES ---
   -> Merging data and computing scores...
--- 4. RUNNING EPOCH ANALYSIS ---
Epoch 0: MIA=96.67% | EM=0.00% | PPL=1.07 | CTX=0.9891
Epoch 1: MIA=90.00% | EM=0.00% | PPL=1.03 | CTX=0.9947
Epoch 2: MIA=100.00% | EM=0.00% | PPL=1.01 | CTX=0.9985
Epoch 3: MIA=56.67% | EM=0.00% | PPL=1.01 | CTX=0.9989
Epoch 4: MIA=56.67% | EM=0.00% | PPL=1.03 | CTX=0.9953
Epoch 5: MIA=50.00% | EM=0.00% | PPL=1.00 | CTX=0.9998
Epoch 6: MIA=53.33% | EM=0.00% | PPL=1.00 | CTX=0.9997
Epoch 7: MIA=66.67% | EM=0.00% | PPL=1.01 | CTX=0.9982
Epoch 8: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 9: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 10: MIA=53.33% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 11: MIA=43.33% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 12: MIA=36.67% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 13: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=0.9999
Epoch 14: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 15: MIA=43.33% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 16: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 17: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 18: MIA=43.33% | EM=0.00% | PPL=1.00 | CTX=1.0000
Epoch 19: MIA=40.00% | EM=0.00% | PPL=1.00 | CTX=1.0000
--- 5. SAVING RESULTS ---
Done. Results in: wikipedia/experiments/run_20251225_005129/results

==================================================================
EXPERIMENT FINISHED SUCCESSFULLY!
Results are available in: wikipedia/experiments/run_20251225_005129/results
    -> Timing: 9h 17m 35s
==================================================================
